%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts to Frontiers, it is not mandatory to use Frontiers .cls files nor frontiers.tex  %
% This will only generate the Manuscript, the final article will be typeset by Frontiers after acceptance.   
%                                              %
%                                                                                                                                                         %
% When submitting your files, remember to upload this *tex file, the pdf generated with it, the *bib file (if bibliography is not within the *tex) and all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Version 3.4 Generated 2018/06/15 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ you can find the packages and how to install them, if necessary. %%%
%%%  NB logo1.jpg is required in the path in order to correctly compile front page header %%%

\documentclass[utf8]{frontiersSCNS} % for Science, Engineering and Humanities and Social Sciences articles
%\documentclass[utf8]{frontiersHLTH} % for Health articles
%\documentclass[utf8]{frontiersFPHY} % for Physics and Applied Mathematics and Statistics articles

%\setcitestyle{square} % for Physics and Applied Mathematics and Statistics articles
\usepackage{url,hyperref,lineno,microtype,subcaption}
\usepackage[onehalfspacing]{setspace}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{ textcomp }
\usepackage{pbox}
\usepackage{xr-hyper}
\usepackage{url}
\usepackage{amssymb}
\usepackage[export]{adjustbox}

\pdfminorversion=7

\externaldocument{frontiers_SupplementaryMaterial}

\lstdefinestyle{myCustomStyle}{
  stepnumber=1,
  numbersep=10pt,
  tabsize=3,
  showspaces=false,
  showstringspaces=false,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space}
}

\lstset{
   basicstyle=\fontsize{8}{10}\selectfont\ttfamily,style=myCustomStyle
}

\linenumbers


% Leave a blank line between paragraphs instead of using \\


\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Osborne {et~al.}} %use et al only if is more than 1 author
\def\Authors{Hugh Osborne\,$^{1}$, Yi Ming Lai\,$^{2}$, Mikkel Elle Lepper{\o}d\,$^{3}$, David Sichau\,$^{4}$, Lukas Deutz\,$^{1}$ and Marc de Kamps\,$^{1,*}$}
% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
% If one of the authors has a change of address, list the new address below the correspondence details using a superscript symbol and use the same symbol to indicate the author in the author list.
\def\Address{$^{1}$Institute for Artificial Intelligence and Biological Computation, School of Computing, University of Leeds, Leeds, United Kingdom \\
$^{2}$School of Medicine, University of Nottingham, Nottingham, United Kingdom \\
$^{3}$Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway \\
$^{4}$Department of Computer Science, ETH Zurich, Zurich, Switzerland }
% The Corresponding Author should be marked with an asterisk
% Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author
\def\corrAuthor{Marc de Kamps}

\def\corrEmail{M.deKamps@leeds.ac.uk}




\begin{document}
\onecolumn
\firstpage{1}

\title[MIIND]{MIIND : A Model-Agnostic Simulator of Neural Populations} 

\author[\firstAuthorLast ]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}

\maketitle

\begin{abstract}

MIIND is a software platform for easily and efficiently simulating the behaviour of interacting populations of point neurons governed by any 1D or 2D dynamical system. The simulator is entirely agnostic to the underlying neuron model of each population and provides an intuitive method for controlling the amount of noise which can significantly affect the overall behaviour. A network of populations can be set up quickly and easily using MIIND’s XML-style simulation file format describing simulation parameters such as how populations interact, transmission delays, post-synaptic potentials, and what output to record. 
During simulation, a visual display of each population’s state is provided for immediate feedback of the behaviour and population activity can be output to a file or passed to a Python script for further processing. The Python support also means that MIIND can be integrated into other software such as The Virtual Brain. MIIND’s population density technique is a geometric and visual method for describing the activity of each neuron population which encourages a deep consideration of the dynamics of the neuron model and provides insight into how the behaviour of each population is affected by the behaviour of its neighbours in the network. For 1D neuron models, MIIND performs far better than direct simulation solutions for large populations. For 2D models, performance comparison is more nuanced but the population density approach still confers certain advantages over direct simulation. MIIND can be used to build neural systems that bridge the scales between an individual neuron model and a population network. This allows researchers to maintain a plausible path back from mesoscopic to microscopic scales while minimising the complexity of managing large numbers of interconnected neurons. In this paper, we introduce the MIIND system, its usage, and provide implementation details where appropriate.

\tiny
 \keyFont{ \section{Keywords:} Simulator, Neural Population, Population Density, Software, Python, Dynamical Systems, Network, GPU} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

\section{Introduction}

\subsection{Population-Level Modeling}
Structures in the brain at various scales can be approximated by simple neural population networks based on commonly observed neural connections. There are a great number of techniques to simulate the behaviour of neural populations with varying degrees of granularity and computational efficiency. 
At the highest detail, individual neurons can be modelled with multiple compartments, transport mechanisms, and other biophysical attributes. Simulators such as GENESIS \citep{wilson1988genesis,bower2012book} and NEURON \citep{hines2001neuron} have been used for investigations of the cerebellar microcircuit \citep{d2016modeling} and a thalamocortical network model \citep{traub2005single}. Techniques which simulate the individual behaviour of point neurons such as in NEST \citep{Gewaltig:NEST}, or the neuromorphic system SpiNNaker \citep{9fed179f612a405b8801b67ef74bc737}, allow neurons to be individually parameterised and connections to be heterogeneous. This is particularly useful for analysing information transfer such as edge detection in the visual cortex. They can also be used to analyse so called finite-size effects where population behaviour only occurs as a result of a specific realisation of individual neuron behaviour. There are, however, performance limitations on very large populations in terms of both computation speed and memory requirements for storing the spike history of each neuron. 

At a less granular level, rate-based techniques are a widely used practice of modeling neural activity with a single variable, whose evolution is often described by first-order ordinary differential equations, which goes back to \cite{wilson1972excitatory}. The Virtual Brain (TVB) uses these types of models to represent activity of large regions (nodes) in whole brain networks to generate efficient simulations \citep{sanz2013virtual,jirsa2014nature}. TVB demonstrates the benefits of a rate based approach with the Epileptor neural population model yielding impressive clinical results \citep{proix2017individual}. The Epileptor model is based on the well known Hindmarsh-Rose neuron model \citep{hindmarsh1984model}. However, the behaviour of this and other rate based models is defined at the population level instead of behaviour emerging from a definition of the underlying neurons. Therefore, these models have less power to explain simulated behaviours at the microscopic level.

Between these two extremes of granularity is a research area which bridges the scales by deriving population level behaviour from the behaviour of the underlying neurons. So called population density techniques (PDTs) have been used for many years \citep{knight1972dynamics,knight1996dynamical,omurtag2000} to describe a population of neurons in terms of a probability density function. The transfer function of a neuron model or even an experimental neural recording can be used to approximate the response from a population using this technique \citep{wilson1972excitatory,el2009master,carlu2020mean}. However, analytical solutions are often limited to regular spiking behaviour with constant or slowly changing input. The software we present here, MIIND, provides a numerical solution for populations of neurons with potentially complex behaviours (for example bursting) receiving rapidly changing noisy input with arbitrary jump sizes. The noise is usually assumed to be shot noise, but can be non-Markovian \citep{lai2017population}. 
It contains a number of features that make it particularly suitable for dynamical systems representing neuronal dynamics, such as an adequate handling of boundary conditions that emerge from the presence of thresholds and reset mechanisms, but is not restricted to neural systems. The dynamical systems can be grouped in large networks, which can be seen as the model of a neural circuit at the population level.

The key idea behind MIIND is shown in Fig. \ref{fig-cloud}A. Here, a population of neurons is simulated. In this case, the neurons are defined by a conductance based leaky-integrate-and-fire neuron model with membrane potential and state of the conductance as the two variables. The neuron's evolution through state space is given by a two-dimensional dynamical system. The positions of individual neurons change in state space, both under the influence of the neuron's endogenous dynamics as determined by the dynamical system and of spike trains arriving from neurons in other populations, which cause rapid transitions in state space that are modeled as instantaneous jumps. For the simulation techniques mentioned earlier involving a large number of individual model neuron instances, a practice that we will refer to as Monte Carlo simulation, the population can be represented as a cloud of points in state space. The approach in MIIND, known as a population density technique (PDT) models the probability density of the cloud, shown in Fig. \ref{fig-cloud} as a heat map, rather than the behaviour of individual neurons. The threshold and reset values of the underlying neuron model are visible in the hard vertical edges of the density in Fig. \ref{fig-cloud}A. In Fig. \ref{fig-cloud}B, the same simulation approach is used for a population of Fitzhugh-Nagumo neurons \citep{fitzhugh1961impulses,nagumo1962active}. The Fitzhugh-Nagumo model has no threshold-reset mechanism and so there are no vertical boundaries to the density. As well as being informative in themselves, common population metrics such as average firing rate and average membrane potential can be quickly calculated from these density functions. 

\subsection{The Case for Population Density Techniques} 
Why use this technique?
\cite{omurtag2000,nykamp2000population,kamps2003simple,iyer2013influence} have demonstrated that PDTs are much faster than Monte Carlo simulation for 1D models; \cite{de2019computational} have shown that while speed is comparable between 2D models and Monte Carlo, memory usage is orders of magnitude lower because no spikes need to be buffered, which accounts for significant memory use in large-scale simulations. In practice, this may make the difference between running a simulation on an HPC cluster or a single PC equipped with a general purpose graphics processing unit (GPGPU).

Apart from simulation speed, PDTs have been important in understanding population level behaviour analytically. Important questions, such as `why are cortical networks stable?' \citep{amit1997model}, `how can a population be oscillatory when its constituent neurons fire sporadically?'
\citep{brunel1999fast}, `how does spike shape influence the transmission spectrum of a population?'\citep{fourcaud2003spike} have been analysed in the context of population density techniques, providing insights that cannot be obtained from merely running simulations. A particularly important question, which has not been answered in full is: `how do rate-based equations emerge from populations of spiking neurons and when is their use appropriate?'. There are many situations where such rate-based equations are appropriate, but some where they are not and their correspondence to the underlying spiking neural dynamics is not always clear \citep{montbrio2015macroscopic,de2013generic}. There is a body of work suggesting that some rate-based equations can be seen as the lowest order of perturbations of a stationary state, and much of this work is PDT-based \citep{wilson1972excitatory,gerstner1998spiking,mattia2002population,mattia2004finite,montbrio2015macroscopic}. MIIND opens the possibility to incorporate these theoretical insights into large-scale network models. For example, we can demonstrate the prediction from \cite{brunel1999fast} that inhibitory feedback on a population can cause a bifurcation and produce resonance. Finally, for a steady state input, the firing rate prediction of a PDT model converges to a transfer function which can be used in artifical spiking neural networks.

\subsection{Population-level Modeling}

For the population density approach we take with MIIND, the time evolution of the probability density function is described by a partial integro-differential equation. We give it here to highlight some of its features, but for an in depth introduction to the formalism and a derivation of the central equations we refer to \cite{omurtag2000}.

\begin{equation}                                        
  \frac{ \partial \rho }{ \partial t } + \frac{\partial}{ \partial \vec{v}} \cdot ( \frac{\vec{F}(\vec{v}) \rho(\vec{v},t)}{\tau} ) = \int_{M} d \vec{v}^{\prime} \left\{ W(\vec{v} \mid \vec{v}^{\prime})\rho(\vec{v'}) - W(\vec{v}^{\prime} \mid \vec{v}  )\rho(\vec{v}) \right\},
\label{eq-balance}                                          
\end{equation}  

$\rho$ is the probability density function defined over a volume of state space, $M$, in terms of time, $t$, and time-dependent variables, $\vec{v}$, under the assumption that the neuronal dynamics of a point model neuron is given by:

\begin{equation}
\tau \frac{ d \vec{v}}{dt} = \vec{F}(\vec{v}), 
\end{equation}

where $\tau$ is the neuron's membrane time constant. Simple models are one-dimensional (1D). 
For the leaky-integrate-and-fire (LIF) neuron: 
\begin{equation}
F(v) = -v,
\end{equation}  
For a quadratic-integrate-and-fire (QIF) neuron:
\begin{equation}
F(v)= v^2 + I,
\end{equation}  
where $v$ is the membrane potential, and $I$ can be interpreted as a bifurcation parameter. More complex models require a higher dimensional state space. Since such a space is hard to visualise and understand, considerable effort has been invested in the creation of effective models. In particular two-dimensional (2D) models are considered to be a compromise that allows considerably more biological realism than LIF or QIF neurons, but which remain amenable to visualisation and analysis, and can often be interpreted geometrically \citep{izhikevich2007dynamical}. Examples are the Izhikevich simple neuron \citep{izhikevich2003simple}, the Fitzhugh-Nagumo neuron \citep{fitzhugh1961impulses,nagumo1962active}, and the adaptive-exponential-integrate-and-fire neuron \citep{brette2005}, incorporating phenomena such as bursting, bifurcations, adaptation, and others that cannot be accounted for in a one dimensional model.

$W(v \mid v^{\prime})$ in Eq. \ref{eq-balance} represents a transition probability rate function. The right hand side of Eq. \ref{eq-balance} makes it a Master equation. Any Markovian process can be represented by a suitable choice of $W$. For example, for shot noise, we have
\begin{equation}   
\label{master_equation}
  W(v^{\prime} \mid v) = \nu (\delta (v^{\prime} - v - h)  - \delta( v - v^{\prime})),  
\end{equation}
where $\nu$ is the rate of the Poisson process generating spike events. The delta functions reflect that an incoming spike causes a rapid change in state space, modeled as an instantaneous jump, $h$. It depends on the particular neural model in what variable the jumps take place. Often models use a so-called delta synapse, such that the jump is in membrane potential. In conductance based models, the incoming spike causes a jump in the conductance variable (Fig. \ref{fig-cloud}A), and the influence of the incoming spike on the potential is then indirect, given by the dynamical system's response to the sudden change in the conductance state.

MIIND produces a numerical solution to Eq. \ref{eq-balance} for arbitrary 1D or 2D versions of $\vec{F}(\vec{v})$ (support for 3D versions is in development), under a broad variety of noise processes. Indeed, the right hand side of Eq. \ref{eq-balance} can be generalised to non-Markov processes which cannot simply be formulated in terms of a transition probability rate function $W$. It is possible to introduce a right hand side that entails an integration over a past history of the density using a kernel whose shape is determined by a non-Markov process \citep{lai2017population}.

\subsection{Quick Start Guide}
\label{section:quickstart}
Before describing the implementation details of MIIND, this section demonstrates how to quickly set up a simulation for a simple E-I network of populations of conductance based neurons using the MIIND Python library. A rudimentary level of Python experience is needed to run the simulation. In most cases, MIIND can be installed via Python pip. Detailed installation instructions can be found in the \textit{README.md} file of the MIIND repository \citep{miindwebsite}. For this example, we will use a pre-written script, \textit{generateCondFiles.py}, to generate the required simulation files which can be found in the \textit{examples/quick\_start} directory of the MIIND repository or can be loaded into a working directory using the following python command.

\begin{lstlisting}
$ python -m miind.loadExamples
\end{lstlisting}

In the \textit{examples/quick\_start} directory, the \textit{generateCondFiles.py} script generates the simulation files, \textit{cond.model} and \textit{cond.tmat}.

\begin{lstlisting}
$ python generateCondFiles.py
\end{lstlisting}

The contents of \textit{generateCondFiles.py} is given in Listing \ref{listing:generatecond}. The two important parts of the script are the neuron model function, in this case named \textit{cond()}, and the call to the MIIND function \textit{grid\_generate.generate()} which takes a number of parameters which are discussed in detail later.

\begin{lstlisting}[language=python,caption={\textit{generateCondFiles.py}}\label{listing:generatecond}]
import miind.grid_generate as grid_generate

def cond(y,t):
    E_r = -65e-3
    tau_m = 20e-3
    tau_s = 5e-3

    v = y[0];
    h = y[1];

    v_prime = ( -(v - E_r) - (h * v) ) / tau_m
    h_prime = -h / tau_s

    return [v_prime, h_prime]

grid_generate.generate(
    func = cond, 
    timestep = 1e-04, 
    timescale = 1, 
    tolerance = 1e-6, 
    basename = 'cond', 
    threshold_v = -55.0e-3, 
    reset_v = -65e-3, 
    reset_shift_h = 0.0, 
    grid_v_min = -72.0e-3, 
    grid_v_max = -54.0e-3, 
    grid_h_min = -1.0, 
    grid_h_max = 2.0, 
    grid_v_res = 200, 
    grid_h_res = 200, 
    efficacy_orientation = 'h')
\end{lstlisting}

The \textit{cond()} function should be familiar to those who have used Python numerical integration frameworks such as \textit{scipy.integrate}. It takes the two time dependent variables defined by $y[0]$ and $y[1]$ and a placeholder parameter, $t$, for performing a numerical integration. In the function, the user may define how the derivatives of each variable are to be calculated. The \textit{generate()} function requires a suitable time step, values for a threshold and reset if needed, and a description of the extent of the state space to be simulated. With this structure, the user may define any two dimensional neuron model. The generated files are then referenced in a second file which describes a network of populations to be simulated. Listing \ref{listing:eixml} shows the contents of \textit{cond.xml} describing an E-I network which uses the generated files from \textit{generateCondFiles.py}.

\begin{lstlisting}[language=xml,caption={\textit{cond.xml}}\label{listing:eixml}]
<Simulation>
     <WeightType>CustomConnectionParameters</WeightType>
     <Algorithms>
          <Algorithm type="GridAlgorithm" name="COND" modelfile="cond.model" tau_refractive="0.0" transformfile="cond_0_0_0_0_.tmat" start_v="-0.065" start_w="0.0" >
               <TimeStep>1e-04</TimeStep>
          </Algorithm>
		  <Algorithm type="RateFunctor" name="ExcitatoryInput">
			   <expression>800.</expression>
		  </Algorithm>
     </Algorithms>
     <Nodes>
		  <Node algorithm="ExcitatoryInput" name="INPUT_E" type="EXCITATORY_DIRECT" />
		  <Node algorithm="ExcitatoryInput" name="INPUT_I" type="EXCITATORY_DIRECT" />
          <Node algorithm="COND" name="E" type="EXCITATORY_DIRECT" />
          <Node algorithm="COND" name="I" type="INHIBITORY_DIRECT" />
     </Nodes>
     <Connections>
		  <Connection In="INPUT_E" Out="E" num_connections="1" efficacy="0.1" delay="0.0"/>
		  <Connection In="INPUT_I" Out="I" num_connections="1" efficacy="0.1" delay="0.0"/>
          <Connection In="E" Out="I" num_connections="1" efficacy="0.1" delay="0.001"/>
          <Connection In="E" Out="E" num_connections="1" efficacy="0.1" delay="0.001"/>
          <Connection In="I" Out="E" num_connections="1" efficacy="-0.1" delay="0.001"/>
          <Connection In="I" Out="I" num_connections="1" efficacy="-0.1" delay="0.001"/>
     </Connections>
     <Reporting>
          <Display node="E" />
          <Display node="I" />
          <Rate node="E" t_interval="0.001" />
          <Rate node="I" t_interval="0.001" />
     </Reporting>
     <SimulationRunParameter>
          <SimulationName>EINetwork</SimulationName>
          <t_end>0.2</t_end>
          <t_step>1e-04</t_step>
          <name_log>einetwork.log</name_log>
     </SimulationRunParameter>
</Simulation>
\end{lstlisting}

The full syntax documentation for MIIND XML files is given in section \ref{section:xmlfile}. Though more compact or flexible formats are available, XML was chosen as a formatting style due to its ubiquity ensuring the majority of users will already be familiar with the syntax. The \textit{Algorithms} section is used to declare specific simulation methods for one or more populations in the network. In this case, a GridAlgorithm named \textit{COND} is set up which references the \textit{cond.model} and \textit{cond.tmat} files. A RateFunctor algorithm produces a constant firing rate. In the \textit{Nodes} section, two instances of \textit{COND} are created: one for the excitatory and inhibitory populations respectively. Two \textit{ExcitatoryInput} nodes are also defined. The \textit{Connections} section allows us to connect the input nodes to the two conductance populations. The populations are connected to each other and to themselves with a 1ms transmission delay. The remaining sections are used to define how the output of the simulation is to be recorded, and to provide important simulation parameters such as the simulation time. By running the following python command, the simulation can be run.

\begin{lstlisting}[caption={Run the cond.xml simulation.}]
$ python -m miind.run cond.xml
\end{lstlisting}

The probability density plots for both populations will be displayed in separate windows as the simulation progresses. The firing rate of the excitatory population can be plotted using the following commands. Fig. \ref{fig:quickstart} shows the probability density plots for both populations and average firing rate of population E.

\begin{lstlisting}[caption={Load the cond.xml simulation and plot the average firing rate of population E.}]
$ python -m miind.miindio sim cond.xml
$ python -m miind.miindio rate E
\end{lstlisting}

Finally, the density function of each population can be plotted as a heat map for a given time in the simulation.

\begin{lstlisting}[caption={Plot the probability density of population I at time 0.12s.}]
$ python -m miind.miindio plot-density I 0.12
\end{lstlisting}

Later sections will show how the MIIND simulation can be imported into a user defined Python script so that input can be dynamically set during simulation and population activity can be captured for further processing. 

\section{The MIIND Grid Algorithm}
\label{gridalgorithm}
MIIND allows the user to simulate populations of any 1D or 2D neuron model. Although much of MIIND’s architecture is agnostic to the integration technique used to simulate each population, the system is primarily designed to make use of its novel population density techniques, grid algorithm and mesh algorithm. Both algorithms use a discretisation of the underlying neuron model's state space such that each discrete ``cell'', which covers a small area of state space, is considered to hold a uniform distribution of probability mass. In both algorithms, MIIND performs three important steps for each iteration. First, probability mass is transferred from each cell to one or more other cells according to the dynamics of the underlying neuron model in the absence of any input. The probability mass is then spread across multiple other cells due to incoming random spikes. Finally, if the underlying neuron model has a threshold-reset mechanic, such as an integrate and fire model, probability mass which has passed the threshold is transferred to cells along the reset potential. As it is the most practically convenient method for the user, we will first introduce the grid algorithm. We will discuss its benefits and weaknesses, indicating where it may be appropriate to use the mesh algorithm instead.

\subsection{Generating the Grid and Transition Matrix}
\label{gridgenerate}
To discretise the state space in the grid method, the user can specify the size and $M\times N$ resolution of a rectangular grid which results in $MN$ identical rectangular cells, each of which will hold probability mass. In the grid algorithm, a transition matrix lists the proportion of mass which moves from each cell to (usually) adjacent cells in one time step due to the deterministic dynamics of the underlying neural model. To pre-calculate the transitions for each cell, MIIND first translates the vertices of every cell by integrating each point forward by one time step according to the dynamics of the underlying neuron model as shown in Fig. \ref{fig:grid}A. As the time step is small, a single Euler step is usually all that is required to avoid large errors (although other integration schemes can be used if required). Each transformed cell is no longer guaranteed to be a rectangle and is compared to the original non-transformed grid to ascertain which cells overlap with the newly generated quadrilateral. An overlap indicates that some proportion of neurons in the original cell will move to the overlapping cell after one time step. In order to calculate the overlap, the algorithm in Listing \ref{lst:geometricmethod} is employed. This algorithm is also used in the geometric method of generating transition matrices for the mesh algorithm shown later.

\begin{lstlisting}[caption={A pseudo-code representation of the algorithm used to calculate the overlapping areas between transformed grid cells and the original grid (or for translated cells of a mesh). The proportion of the area of the original cell gives the proportion of probability mass to be moved in each transition. }\label{lst:geometricmethod}]
For each transformed cell, A, in the grid:
	Translate all four vertices according to a single Euler step.
	Split A into two triangles and add them to a triangle list.
For each non-transformed cell, B:
	Set the overlapping area sum to 0.
		While the triangle list has changed:
		For each triangle in the list:
			 If the triangle is entirely outside B: add 0 to the sum.
			 If the triangle is entirely within B: add the triangle's area to the sum.
			 If B is entirely within the triangle: add B's area to the sum.
			 Else: For each edge in B:
				Calculate any intersection points with the edges of the triangle.
				Triangulate the polygon produced by the original triangle points plus the new intersection points.
				Remove the original triangle from the list.
				Add the newly generated triangles to the list.
		Calculate the proportion of A taken by the sum.
		Add the transition from A to B with the proportion to the transition matrix.	
\end{lstlisting}

Though the pseudo-code algorithm is order $N^2$, there are many ways that the efficiency of the algorithm is improved in the implementation. The number of non-transformed cells checked for overlap can be limited to only those which lie underneath each given triangle. Furthermore, the outer loop is parallelisable. Finally, as the non-transformed cells are axis-aligned rectangles, the calculation to find edge intersections is trivial. Fig. \ref{fig:grid}A shows a fully translated and triangulated cell at the end of the algorithm. Once the transition matrix has been generated, it is stored in a file with the extension \textit{.tmat}. Although the regular grid can be described with only four parameters (the width, height, X, and Y resolutions), to more closely match the behaviour of mesh algorithm, the vertices of the grid are stored in a \textit{.model} file. To simulate a population using the grid algorithm, the \textit{.tmat} and \textit{.model} files must be generated and referenced in the XML simulation file.

As demonstrated in the quick start guide (section \ref{section:quickstart}), to generate a \textit{.model} and \textit{.tmat} file, the user must write a short Python script which defines the underlying neuron model and makes a call to the MIIND API to run the algorithm in listing \ref{lst:geometricmethod}. In the \textit{python} directory of the MIIND source repository (see section \ref{directorystructure} in the supplementary material), there are a number of examples of these short scripts. The script used to generate a grid for the Izhikevich simple model is listed in the supplementary material section \ref{izhmesh}. The required definition of the neuron model function is similar to those used by many numerical integration libraries. The function takes a parameter, $y$, which represents a list which holds the two time dependent variables and a parameter, $t$, which is a placeholder for use in integration. The function must return the first time derivatives of each variable as a list in the same order as in $y$. Once the function has been written, a call to \textit{grid\_generate.generate} is made which takes the parameters listed in Table \ref{tab:gridgenerate}. 

When the user runs the script, the required \textit{.model} and \textit{.tmat} files will be generated for use in a simulation. In the quick start guide, the conductance based neuron model requires that \textit{efficacy\_orientation} is set to `h' because incoming spikes cause an instantaneous change in the conductance variable instead of the membrane potential. By default, however, this parameter is set to `v'. When choosing values for the grid bounds (\textit{grid\_v\_min}, \textit{grid\_v\_max}, \textit{grid\_h\_min}, and \textit{grid\_h\_max}), the aim is to estimate where in state space the population density function might be non-zero during a simulation. In the conductance based neuron model, because of the threshold-reset mechanic, the \textit{grid\_v\_max} parameter need only be slightly above the threshold to ensure that there is at least one column of cells on or above threshold to allow probability mass to be reset. The \textit{grid\_v\_min} value should be below the resting potential and reset potential. However, we must also consider that the neurons could receive inhibitory spikes which would cause the neurons to hyperpolarise. \textit{grid\_v\_min} should therefore be set to a value beyond the lowest membrane potential expected during the simulation. Similarly for the conductance variable, space should be provided for reasonable positive and negative values. If it is known beforehand that no inhibition will occur, however, then the state space bounds can be set tighter in order to improve the accuracy of the simulation using the same grid resolution (\textit{grid\_v\_res} and \textit{grid\_h\_res}). If, during the simulation, probability mass is pushed beyond the lower bounds of the grid, it will be pinned at those lower bounds which will produce incorrect behaviour and results. If the probability mass is pushed beyond the upper bounds, it will be wrapped around to the lower bounds which will also produce incorrect results. The choice of grid resolution is a balance between speed of simulation and accuracy. However, even very coarse grids can produce representative firing rates and behaviours. Typical grid resolutions range between 100x100 and 500x500. It can also be beneficial to experiment with different $M$ and $N$ values as the accuracy of each dimension can have unbalanced influence over the population level metrics. \\

\subsection{The Effect of Random Incoming Spikes}
The transition matrix in the \textit{.tmat} file describes how probability mass moves to other cells due to the deterministic dynamics of the underlying neuron model. The transition matrix is sparse as probability mass is often only transferred to nearby cells. Solving the deterministic dynamics is therefore very efficient. The mesh algorithm is even faster and, as demonstrated later, is significantly quicker than direct simulation for this part of the algorithm. Another benefit to the modeler is that by rendering the grid with each cell coloured according to its mass, the resultant heat map gives an excellent visualisation of the state of the population as a whole at each time step of the simulation as shown in Fig. \ref{fig:quickstart}. This provides particularly useful insight into the sub-threshold behaviour of neurons in the population.

The second step of the grid algorithm, which must be performed every iteration, is to solve the change in the probability density function due to random incoming spikes. It is assumed that a spike causes an instantaneous change in the state of a neuron, usually a step wise jump in membrane potential corresponding to a constant synaptic efficacy. In the conductance based neuron example, this jump is in the conductance. When considering each cell in the grid, a single incoming spike will cause some proportion of the probability mass to shift to at most, two other cells as shown in Fig. \ref{fig:grid}. Because all cells in the grid are equally distributed and the same size, the relative transition of probability mass caused by a single spike is the same for them all. A sparse transition matrix, $M$, can be generated from this single transition so that applying $M$ to the probability density grid applies the transition to all cells. MIIND calculates a different $M$ for each incoming connection to the population based on the user defined instantaneous jump, which we refer to as the efficacy. In the mesh algorithm, the relative transitions are different for each cell and so a transition matrix (similar to that of the \textit{.tmat} file) is required to describe the effect of a single spike. As with many other population density techniques, MIIND assumes that incoming spikes are Poisson distributed, although it is possible to approximate other distributions. MIIND uses $M$ to calculate the change to the probability density function, $\rho$, due solely to the non-deterministic dynamics as described by equation \ref{eq:masterprocess}.

\begin{equation}  
d\rho/dt = \lambda M \rho \\
\label{eq:masterprocess}
\end{equation}

$\lambda$ is the incoming Poisson firing rate. The boost numeric library is used to integrate $d\rho/dt$. The solution to this equation describes the spread of the probability density due to Poisson spikes. This `master process' step amounts to multiple applications of the transition matrix $M$ and is where the majority of time is taken computationally. However, OpenMP is available in MIIND to parallelise the matrix multiplication. If multiple cores are available, the OpenMP implementation significantly improves performance of the master process step. More information covering this technique can be found in \cite{de2019computational,de2013generic}.\\

\subsection{Threshold-Reset Dynamics}
Many neuron models include a ``threshold-reset’’ process such that neurons which pass a certain membrane potential value are shifted back to a defined reset potential to approximate repolarisation during an action potential. To facilitate this in MIIND, after each iteration, probability mass in cells which lie across the threshold potential is relocated to cells which lie across the reset potential according to a pre-calculated mapping. Often, a refractory period is used to hold neurons at the reset potential before allowing them to again receive incoming spikes. In MIIND this is implemented using a queue for each threshold cell as shown in Fig. \ref{fig:basicreset}. The queues are set to the length of the refractory period divided by the time step, rounded up to the nearest integer value. During each iteration, probability mass is shifted one position along the queue. A linear interpolation of the final two places in the queue is made and this value is passed to the mapped reset cell. The interpolation is required in case the refractory period is not an integer multiple of the time step. The total probability mass in the threshold cells each iteration is used to calculate the average population firing rate. For models which do not require threshold-reset dynamics, setting the threshold value to the maximal membrane potential of the grid, and the reset to the minimal membrane potential ensures that no resetting of probability mass will occur.\\

\subsection{How MIIND Facilitates Interacting Populations}
The grid algorithm describes how the behaviour of a single population is simulated. The MIIND software platform as a whole provides a way for many populations with possibly many different integration algorithms to interact in a network. The basic process of simulating a network is as follows. The user must write an XML file which describes the whole simulation. This includes defining the population nodes of the network and how they are connected; which integration technique each population uses (grid algorithm, mesh algorithm etc.); external inputs to the network; how the activity of each population will be recorded and displayed; the length and time step of the simulation. As shown in the quick start guide, the XML file can be passed as a parameter to the \textit{miind.run} module in Python. When the simulation is run, a population network is instantiated and the simulation loop is started. For each iteration, the output activity of each population node is recorded. By default, the activity is assumed to be an average firing rate but other options are available such as average membrane potential. The outputs are passed as inputs to each population node according to the connectivity defined in the XML file. Each population is evolved forward by one time step and the simulation loop repeats until the simulation time is up. The Python front end, \textit{miind.miindio}, provides the user with tools to analyse the output from the simulation. A custom \textit{run} script can also be written by the user to perform further analysis and processing.

The simplicity of the XML file means that a user can set up a large network of populations with very little effort. The model archive in the code repository holds a set of example simulations demonstrating the range of MIIND's functionality and includes an example which simulates the Potjans-Diesmann model of a cortical microcircuit \citep{potjans2014cell}, which is made up of eight populations of leaky integrate and fire neurons. Fig. \ref{fig:potjans} shows a representation of the model with embedded density plots for each population.\\

\subsection{Running MIIND Simulations}
The quick start guide demonstrated the simplest way to run a simulation given that the required \textit{.model}, \textit{.tmat}, and \textit{.XML} files have been generated. The \textit{miind.run} script imports the \textit{miind.miindsim} Python extension module which can also be imported into any user written Python script. Section \ref{miindpython} details the functions which are exposed by \textit{miind.miindsim} for use in a python script. The benefit of this method is that the outputs from populations can be recorded after each iteration and inputs can be dynamic allowing the python script to perform its own logic on the simulation based on the current state.

There is also a command line interface (CLI) program provided by the Python module, \textit{miind.miindio}. The CLI can be used for many simple work flow tasks such as generating models and displaying results. Each command which is available in the CLI, can also be called from the MIIND Python API, upon which the CLI is built. A full list of the available commands in the CLI is given in section \ref{clilisting} of the supplementary material and a worked example using common CLI commands is provided in section \ref{workflow}. \\

\subsection{When not to use the Grid Algorithm}
For many underlying neuron models, the grid algorithm will produce results showing good agreement with direct simulation to a greater or lesser extent depending on the resolution of the grid (see Fig. \ref{fig:gridcomp}). However, for models such as exponential integrate and fire, a significantly higher grid resolution is required than might be expected because of the speed of the dynamics across the threshold (beyond which, neurons perform the action potential). When the input rate is high enough to generate tonic spiking in an exponential integrate and fire model, the rate of depolarisation of each neuron reduces as it approaches the threshold potential then once it is beyond the threshold, quickly increases producing a spike. Because the grid discretises the state space into regular cells, if cells are large due to a low resolution, only a small number of cells will span the threshold, as shown in Fig. \ref{fig:meshissue}A. When the transition matrix is applied each time step, probability mass is distributed uniformly across each cell. Probability mass can therefore artificially cross the threshold much faster than it should leading to a higher than expected average firing rate for the population. Using the grid algorithm for such models where the firing rate itself is dependent on sharp changes in the speed of the dynamics should be avoided if high accuracy is required. Other neuron models, like the busting Izhikevich simple model, also have sharp changes in speed when neurons transition from bursting to quiescent periods. However, the bursting firing rate is unaffected by these dynamics and the oscillation frequency is affected only negligibly due to the difference in timescales. The grid algorithm is therefore still appropriate in cases such as this. For exponential integrate and fire models, however, MIIND provides a second algorithm which can more accurately capture the deterministic dynamics: mesh algorithm. 

\section{The MIIND Mesh Algorithm}
\label{miindoverview}
Instead of a regular grid to discretise the state space of the underlying neuron model, the mesh algorithm requires a two dimensional mesh which describes the dynamics of the neuron model itself in the absence of incoming spikes. A mesh is constructed from strips which follow the trajectories of neurons in state space (Fig. \ref{fig:strip}). The trajectories form so-called characteristic curves of the neuron model from which this method is inspired \citep{de2019computational,de2013generic}.

These trajectories are computed as part of a one-time preprocessing step using an appropriate integration technique and time step. Strips will often approach or recede from nullclines and stationary points and their width may shrink or expand according to their proximity to such elements. Each strip is split into cells. Each cell represents how far along the strip neurons will move in a single time step. As with the width of the strips, cells will become more dense or more sparse as the dynamics slow down and speed up respectively. The result of covering the state space with strips is a precomputed description of the model dynamics such that the state of a neuron in one cell of the mesh is guaranteed to be in the next cell along the strip after a single time step. Depending on the underlying neuron model, it can be difficult to get full coverage without cells becoming too small or shear. However, once built, the deterministic dynamics have effectively been ``pre-solved’’ and baked into the mesh.

As with the grid algorithm, when the simulation is running, each cell is associated with a probability mass value which represents the probability of finding a neuron from the population with a state in that cell. When a probability density function (PDF) is defined across the mesh, computing the change to the PDF due to the deterministic dynamics of the neurons is simply a matter of shifting each cell's probability mass value along its strip. In the C++ implementation, this requires no more than a pointer update and is therefore quicker than the grid algorithm for solving the deterministic dynamics as no transition matrix is applied to the cells.

Mesh algorithm does, however, still require a transition matrix to implement the effect of incoming spikes on the PDF. This transition matrix describes how the state of neurons in each cell are translated in the event of a single incoming spike. Unlike the grid algorithm, cells are unevenly distributed across the mesh and are different sizes and shapes. What proportion of probability mass is transferred to which cells with a single incoming spike is, therefore, different for all cells. During simulation, the total change in the PDF is calculated by shifting probability mass one cell down each strip and using the transition matrix to solve the master equation every time step. The combined effect can be seen in Fig. \ref{fig:desities}. The method of solving the master equation is explained in detail in \cite{de2013generic}.

\subsection{When not to use the Mesh Algorithm} 
Just as with the grid algorithm, certain neuron models are better suited to an alternative algorithm. In the mesh algorithm, very little error is introduced for the deterministic dynamics. Probability mass flows down each strip as it would without the discretisation and error is limited only to the size of the cells. When the master equation is solved, however, probability mass can spread to parts of state space which would see less or no mass. Fig. \ref{fig:meshissue}B demonstrates how in the mesh algorithm, as probability mass is pushed horizontally, very shear cells can allow mass to be incorrectly transferred vertically as well. In the the grid algorithm, error is introduced in the opposite way. Solving the master equation pushes probability mass along horizontal rows of the grid and error is limited to the width of the row. The grid algorithm is preferable over the mesh algorithm for populations of neurons with one fast variable and one slow variable which can produce very shear cells in a mesh, e.g. in the Fitzhugh-Nagumo model \citep{de2019computational}. In both algorithms, the error can be reduced by increasing the density of cells (by increasing the resolution of the grid, or by reducing the timestep and strip width of the mesh). However, better efficiency is achieved by using the appropriate algorithm.

\subsection{Building a Mesh for the Mesh Algorithm}
\label{generatemodelmatfiles}
Before a simulation can be run for a population which uses the mesh algorithm, the pre-calculation steps of generating a mesh and transition matrices must be performed. Fig. \ref{fig:meshworkflow} shows the full pre-processing pipline for mesh algorithm. The mesh is a collection of strips made up of quadrilateral cells. As mentioned earlier, probability mass moves along a strip from one cell to the next each time step which describes the deterministic dynamics of the model. Defining the cells and strips of a 2D mesh is not generally a fully automated process and the points of each quadrilateral must be defined by the mesh developer and stored in a $.mesh$ file. When creating the mesh, the aim is to cover as much of the state space as possible without allowing cells to get too small or misshapen. An example of a full mesh generation script for the Izhikevich simple neuron model \citep{izhikevich2003simple} is available in section \ref{izhmesh} of the supplementary material. MIIND provides \textit{miind.miind\_api.LifMeshGenerator}, \textit{miind.miind\_api.QifMeshGenerator}, and \textit{miind.miind\_api.EifMeshGenerator} scripts to automatically build the 1D leaky integrate and fire, quadratic integrate and fire, and exponential integrate and fire neuron meshes respectively. They can be called from the CLI. The scripts generate the three output files which any mesh generator script must produce: a \textit{.mesh} file, a \textit{.stat} file which defines extra cells in the mesh to hold probability mass that has settled at a stationary point, and a \textit{.rev} file which defines a ``reversal mapping'' indicating how probability mass is transferred from strips in the mesh to the stationary cells. More information on \textit{.mesh}, \textit{.stat}, and \textit{.rev} files is provided in the supplementary material section \ref{suppl:meshbuilding}. 

Once the \textit{.mesh}, \textit{.stat}, and \textit{.rev} files have been generated by the user or by one of the automated 1D scripts, the Python command line interface, \textit{miind.miindio}, provides commands to convert the three files into a single \textit{.model} file and generate transition matrices stored in \textit{.mat} files. The model file is what will be referenced and read by MIIND to load a mesh for a simulation. To generate this file, use the CLI command, \textbf{generate-model}. The command parameters are shown in Table \ref{tab:generatemodel}. All input files must have the same base name, for example: \textit{lif.mesh}, \textit{lif.stat}, and \textit{lif.rev}. If the command runs successfully, a new file will be created: \textit{basename.model}. A number of pre-generated models are available in the \textit{examples} directory of the MIIND repository to be used ``out of the box'' including the adaptive exponential integrate and fire and conductance based neuron models.

\begin{lstlisting}[language=xml,caption={Generate a Model in the CLI}]
> generate-model lif -60.0 -30.0
\end{lstlisting}

The generated \textit{.model} file contains the mesh vertices, some summary information such as the time step used to generate the mesh and the threshold and reset values, and a mapping of threshold cells to reset cells.

In the the mesh algorithm, transition matrices are used to solve the Poisson master equation which describes the movement of probability mass due to incoming random spikes. In the mesh algorithm, one transition matrix is required for each post synaptic efficacy that will be needed in the simulation. So if a population is going to receive spikes which cause jumps of 0.1mV and 0.5mV, two transition matrices are required. It is demonstrated later how the efficacy can be made dependent on the membrane potential or other variables. Each transition matrix is stored in a \textit{.mat} file and contains a list of source cells, target cells, and proportions of probability mass to be transferred to each. For a given cell in the mesh, neurons with a state inside that cell which receive a single external spike will shift their location in state space by the value of the efficacy. Neurons from the same cell could therefore end up in many other different cells, though often ones which are nearby. It is assumed that neurons are distributed uniformly across the source cell. Therefore, the proportion of neurons which end up in each of the other cells can be calculated. MIIND performs this calculation in two ways, the choice for which is given to the user.

The first method is to use a Monte Carlo approach such that a number of points are randomly placed in the source cell then translated according to the efficacy. A search takes place to find which cells the points were translated to and the proportions are calculated from the number of points in each. For many meshes, a surprisingly small number of points, around 10, is required in each cell to get a good approximation for the transition matrix and the process is therefore quite efficient. As shown in Fig. \ref{fig:meshworkflow}, an additional process is required when generating transition matrices using Monte Carlo which includes two further intermediate files, \textit{.fid} and \textit{.lost}. All points must be accounted for when performing the search and in cases where points are translated outside of the mesh, an exhaustive search must be made to find the closest cell. The \textbf{lost} command allows the user to speed up this process which is covered in detail in section \ref{suppl:montecarlo} of the supplementary material.

The second method translates the actual vertices of each cell according to the efficacy and calculates the exact overlapping area with other cells. The method by which this is achieved is the same as that used to generate the transition matrix of the grid algorithm, described in section \ref{gridgenerate}. This method provides much higher accuracy than Monte Carlo but is one order of magnitude slower (it takes a similar amount of time to perform Monte Carlo with 100 points per cell). For some meshes, it is crucial to include very small transitions between cells to properly capture the dynamics which justifies the need for the slower method. It also benefits from requiring no additional user input in contrast to the Monte Carlo method.

In \textit{miind.miindio}, the command \textbf{generate-matrix} can be used to automatically generate each \textit{.mat} file. In order to work, there must be a \textit{basename.model} file in the working directory. The \textbf{generate-matrix} command takes six parameters which are described in Table \ref{tab:generatematrix}. Listing \ref{lst:generatematrix} shows an example of the \textbf{generate-matrix} command. If successful, two files are generated: $basename.mat$ and $basename.lost$.

\begin{lstlisting}[language=xml,caption={The \textit{miind.miindio} command to generate a matrix using the adex.model file with an efficacy of 0.1 in $v$ and a jump of 5.0 in $w$ when a neuron spikes. The Monte Carlo method has been chosen with 10 points per cell.}\label{lst:generatematrix}]
> generate-matrix adex 0.1 10 0.0 5.0 false
\end{lstlisting}

Once \textbf{generate-matrix} has completed, a \textit{.mat} file will have been generated and the \textit{.model} file will have been amended to include a \textit{\textless Reset Mapping\textgreater} section. Similar to the reversal mapping in the \textit{.rev} file, the reset mapping describes movement of probability mass from the cells which lie across the threshold potential to cells which lie across the reset potential. If the threshold or reset values are changed but no other change is made to the mesh, it can be helpful to re-run the mapping calculation without having to completely re-calculate the transition matrix. \textit{miind.miindio} provides the command \textbf{regenerate-reset} which takes the base name and any new reset shift value (0 if not required) as parameters. This will quickly replace the reset mapping in the \textit{.model} file.

\begin{lstlisting}[language=xml,caption={The user may change the \textit{\textless Threshold\textgreater} and \textit{\textless Reset\textgreater} values in the \textit{.model} file (or re-call \textbf{generate-model} with different threshold and reset values) then update the existing Reset Mapping. In this case, the adex.model was updated with a reset $w$ shift value of 7.0.}\label{lst:regeneratereset}]
> regenerate-reset adex 7.0
\end{lstlisting}

With all required files generated, a simulation using the mesh algorithm can now be run in MIIND.

\subsection{Jump Files}
In some models, it is helpful to be able to set the efficacy as a function of the state. For example, to approximate adaptive behaviour where the post synaptic efficacy lowers as the membrane potential increases. Jump files have been used in MIIND to simulate the Tsodyks-Markram \citep{tsodyks1997neural} synapse model as described in \cite{de2019computational}. In the model, one variable/dimension is required to represent the membrane potential, $V$, of the post-synaptic neuron and the second to represent the synaptic contribution, $G$. $G$ and $V$ are then used to derive the post-synaptic potential caused by an incoming spike. Before generating the transition matrix, each cell can be assigned its own efficacy for which the transitions will be calculated. During generation, Monte Carlo points will be translated according to that value instead of a constant across the entire mesh. When calling the \textbf{generate-matrix} command, a separate set of three parameters is required to use this feature. The base name of the model file, the number of Monte Carlo points per cell, and a reference to a \textit{.jump} file which stores the efficacy values for each cell in the mesh. 

\begin{lstlisting}[language=xml,caption={Generate a transition matrix with a jump file in the CLI}]
> generate-matrix adex 10 adex.jump
\end{lstlisting}

As with the files required to build the mesh, the jump file must be user generated as the efficacy values may be non-linear and involve one or both of the dimensions of the model. The format of a jump file is shown in listing \ref{lst:jumpformat}. The \textit{\textless Efficacy\textgreater} element of the XML file gives an efficacy value for both dimensions of the model and is how the resulting transition matrix will be referenced in the simulation. The \textit{\textless Translations\textgreater} element lists the efficacy in both dimensions for each cell in the mesh.

\begin{lstlisting}[language=xml,caption={The format of the jump file. Each line in the  \textit{\textless Translations\textgreater} block gives the strip,cell coordinates of the cell followed by the $h$ efficacy then the $v$ efficacy. The \textit{\textless Efficacy\textgreater} element gives a reference efficacy which will be used to reference the transition matrix built with this jump file. It must therefore be unique among jump files used for the same model.}\label{lst:jumpformat}]
<Jump>
<Efficacy>0.0 0.1</Efficacy>
<Translations>
0,0	0.0	0.1
1,0	0.0	0.1
1,1	0.0	0.10012
1,2	0.0	0.10045
...
</Translations>
</Jump>
\end{lstlisting}

After calling \textbf{generate-matrix}, as before, the \textit{.mat} file will be created with the quoted values in the \textit{\textless Efficacy\textgreater} element of the jump file. As with the vanilla Monte Carlo generation, the additional process of tracking lost points must be performed. 

\section{Writing the XML File}
\label{section:xmlfile}
MIIND provides an intuitive XML style language to describe a simulation and its parameters. This includes descriptions of populations, neuron models, integration techniques, and connectivity as well as general parameters such as time step and duration. The XML file is split into sections which are sub elements of the XML root node, \textit{\textless Simulation\textgreater}. They are Algorithms, Nodes, Connections, Reporting, and SimulationRunParameter. These elements make up the major components of a MIIND simulation.

\subsection{Algorithms}

An \textit{\textless Algorithm\textgreater} in the XML code describes the simulation method for a population in the network. The nodes of the network represent separate instances of these algorithm elements. Therefore, many nodes can use the same algorithm. Each algorithm has different parameters or supporting files but as a minimum, all algorithms must declare a type and a name. Each algorithm is also implicitly associated with a ``weight type’’. All algorithms used in a single simulation must be compatible with the weight type as it describes the way that populations interact. The \textit{\textless WeightType\textgreater} element of the XML file can take the values, ``double’’, ``DelayedConnection’’, or ``CustomConnectionParameters’’. Which value the weight type element takes influences which algorithms are available in the simulation and how the connections between populations will be defined. The following sections cover all Algorithm types currently supported in MIIND. Table \ref{tab:algorithmweighttypes} lists these algorithms and their compatible weight types.

\subsubsection{RateAlgorithm}

RateAlgorithm is used to supply a Poisson distributed input (with a given average firing rate) to other nodes in the simulation. It is typically used for simulating external input. The \textit{\textless rate\textgreater} sub-element is used to define the activity value which is usually a firing rate. 

\begin{lstlisting}[caption={A RateAlgorithm definition with a constant rate of 100Hz.}]
<Algorithm name="Cortical Background Algorithm" type="RateAlgorithm">
	<rate>100.0</rate>
</Algorithm>
\end{lstlisting}

\subsubsection{MeshAlgorithm and MeshAlgorithmCustom}

In section \ref{generatemodelmatfiles}, we saw how to generate \textit{.model} and \textit{.mat} files. These are required to simulate a population using the mesh algorithm. Algorithm type=MeshAlgorithm tells MIIND to use this technique. The model file is referenced as an attribute to the Algorithm definition. The \textit{TimeStep} child element must match that which was used to generate the mesh. This value is quoted in the model file. As many \textit{MatrixFile} elements can be declared as are required for the simulation, each with an associated .mat file reference.

\begin{lstlisting}[language=xml,caption={A MeshAlgorithm definition with two matrix files.}]
<Algorithm type="MeshAlgorithm" name="ALG_ADEX" modelfile="adex.model" >
	<TimeStep>0.001</TimeStep>
	<MatrixFile>adex_0.05_0_0_0_.mat</MatrixFile>
	<MatrixFile>adex_-0.05_0_0_0_.mat</MatrixFile>
</Algorithm>
\end{lstlisting}

MeshAlgorithm provides two further optional attributes in addition to \textit{modelfile}. The first is \textit{tau\_refractive} which enables a refractory period and the second is \textit{ratemethod} which takes the value ``AvgV’’ if the activity of the population is to be represented by the average membrane potential. Any other value for \textit{ratemethod} will set the activity to the default average firing rate. The activity value is what will be passed to other populations in the network as well as what will be recorded as the activity for any populations using this algorithm.

When the weight type is set to CustomConnectionParameters, the type of this algorithm definition should be changed to MeshAlgorithmCustom. No other changes to the definition are required.

\subsubsection{GridAlgorithm and GridJumpAlgorithm}

For populations which use the grid algorithm, the following listing is required. Similar to the MeshAlgorithm, the model file is referenced as an attribute. However, there are no matrix files required as the transition matrix for solving the Poisson master equation is calculated at run time. The transition matrix for the deterministic dynamics, stored in the \textit{.tmat} file, is referenced as an attribute as well. Attributes for \textit{tau\_refractive} and \textit{ratemethod} are also available with the same effects as for MeshAlgorithm. 

\begin{lstlisting}[language=xml,caption={A GridAlgorithm definition using the AvgV (membrane potential) rate method.}]
<Algorithm type="GridAlgorithm" name="GRIDALG_FN" modelfile="fn.model" tau_refractive="0.0" transformfile="fn_0_0_0_0_.tmat" start_v="-1.0" start_w="-0.3" ratemethod="AvgV">
<TimeStep>0.00001</TimeStep>
</Algorithm>
\end{lstlisting}

GridAlgorithm also provides additional attributes \textit{start\_v} and \textit{start\_w} which allows the user to set the starting state of all neurons in the population which creates an initial probability mass of 1.0 in the corresponding grid cell at the start of the simulation.

GridJumpAlgorithm provides a similar functionality as MeshAlgorithm when the transition matrix is generated using a jump file. That is, the efficacy applied to each cell when calculating transitions differs from cell to cell. In GridJumpAlgorithm, the efficacy at each cell is multiplied by the distance between the central $v$ value of the cell and a user defined ``stationary'' value. The initial efficacy and the stationary values are defined by the user in the XML \textit{\textless Connection\textgreater} elements. GridJumpAlgorithm is useful for approximating populations of neurons with a voltage dependent synapse.

\begin{lstlisting}[language=xml,caption={A GridJumpAlgorithm definition and corresponding Connection with a ``stationary'' attribute. The efficacy at each grid cell will equal the original efficacy value (-0.05) multiplied by the difference between each cell's central v value and the given stationary value (-65)}]
<Algorithm type="GridJumpAlgorithm" name="ALG_ADEX" modelfile="adex.model" tau_refractive="0.0" transformfile="adex_0_0_0_0_.tmat" start_v="-65.0" start_w="0.0">
<TimeStep>0.0001</TimeStep>
</Algorithm>
...
<Connection In="BG_NOISE" Out="ADEX_NODE" num_connections="1" efficacy="-0.05" delay="0.0" stationary="-65.0"/>
\end{lstlisting}

\subsubsection{Additional Algorithms}
MIIND also provides OUAlgorithm and WilsonCowanAlgorithm. The OUAlgorithm generates an Ornstein–Uhlenbeck process \citep{uhlenbeck1930theory} for simulating a population of LIF neurons. The WilsonCowanAlgorithm implements the Wilson-Cowan model for simulating population activity \citep{wilson1972excitatory}. Examples of these algorithms are provided in the examples directory of the MIIND repository (\textit{examples/twopop} and \textit{examples/model\_archive/WilsonCowan}).

One final algorithm, RateFunctor, behaves similarly to RateAlgorithm. However, instead of a rate value, the child value defines the activity using a C++ expression in terms of variable, $t$, representing the simulation time.

\begin{lstlisting}[caption={A RateFunctor algorithm definition in which the firing rate linearly increases to 100Hz over 0.1 seconds and remains at 100Hz thereafter.}]
<Algorithm type="RateFunctor" name="ExternalInput">
	<expression><![CDATA[ t < 0.1 ? (t/0.1)*100 : 100 ]]></expression>
</Algorithm>
\end{lstlisting}

A CDATA expression is not permitted when using MIIND in Python or when calling \textit{miind.run}. However, RateFunctor can still be used with a constant expression (although this has no benefit beyond what RateAlgorithm already provides). CDATA should only be used when MIIND is built from source (not installed using pip) and the MIIND API is used to generate C++ code from an XML file.

\subsection{Nodes}

The \textit{\textless Node\textgreater} block lists instances of the Algorithms defined above. Each node represents a single population in the network. To create a node, the user must provide the name of one of the algorithms defined in the algorithm block which will be instantiated. A name must also be given to uniquely identify this node. The type describes the population as wholey inhibitory, excitatory, or neutral. The type dictates the sign of the post synaptic efficacy caused by spikes from this population. Setting the type to neutral allows the population to produce both excitatory and inhibitory (positive and negative) synaptic efficacies. For most algorithms, the valid types for a node are \textit{EXCITATORY}, \textit{INHIBITORY}, and \textit{NEUTRAL}. \textit{EXCITATORY\_DIRECT} and \textit{INHIBITORY\_DIRECT} are also available but mean the same as \textit{EXCITATORY} and \textit{INHIBITORY} respectively.

\begin{lstlisting}[language=xml,caption={Three nodes defined in the Nodes section using the types \textit{NEUTRAL}, \textit{INHIBITORY}, and \textit{EXCITATORY} respectively.}]
<Nodes>
...
<Node algorithm="GRIDALG_FN" name="POP_1" type="NEUTRAL" />
<Node algorithm="ALG_ADEX" name="ADEX_NODE" type="INHIBITORY" />
<Node algorithm="RATEFUNC_BACKGROUND" name="BG_NOISE" type="EXCITATORY" />
...
</Nodes>
\end{lstlisting}

Many nodes can reference the same algorithm to use the same population model but they will behave independently based on their individual inputs.

\subsection{Connections}

The connections between the nodes are defined in the \textit{\textless Connections\textgreater} sub-element. Each connection can be thought of as a conduit which passes the output activity from the ``In'' population node to the ``Out'' population node. The format used to define the connections is dependent on the choice of \textit{WeightType}. When the type is \textit{double}, connections require a single value which represents the connection weight. This will be multiplied by the output activity of the In population and passed to the Out population. The sign of the weight must match the In node’s type definition (\textit{EXCITATORY}, \textit{INHIBITORY}, \textit{NEUTRAL}).

\begin{lstlisting}[language=xml,caption={A simple double WeightType Connection with a single rate multiplier.}]
<WeightType>double</WeightType>
<Connections>
...
<Connection In="RATEFUNC_BACKGROUND" Out="WC_POP">0.1</Connection>
...
</Connections>
\end{lstlisting}

Many algorithms use the \textit{DelayedConnection} weight type which requires three values to define each connection. The first is the number of incoming connections each neuron in the Out population receives from the In population. This number is effectively a weight and is multiplied by the output activity of the In population. For example, if the output firing rate of an In population is 10Hz and the number of incoming connections is set to 10, the effective average incoming spike rate to each neuron in the Out population will be 100 Hz. The second value is the post synaptic efficacy whose sign must match the type of the In population. If the Out population is an instance of MeshAlgorithm, the efficacy must also match one of the provided \textit{.mat} files. The third value is the connection delay in seconds. The delay is implemented in the same way as the refractory period in the mesh and grid algorithms. The output activity of the In population is placed at the beginning of the queue and shifted towards the end of the queue over subsequent iterations. The input to the Out population is taken as the linear interpolation between the final two values in the queue. 

\begin{lstlisting}[language=xml,caption={A DelayedConnection with number of connections = 10, efficacy = 0.1, and delay of 1ms.}]
<WeightType>DelayedConnection</WeightType>
<Connections>
...
<Connection In="RATEFUNC_BACKGROUND" Out="BURSTER">10 0.1 0.001</Connection>
...
</Connections>
\end{lstlisting}

With the addition of GridAlgorithm, there was a need for a more flexible connection type which would allow custom parameters to be applied to each connection. When using the \textit{CustomConnectionParameters} weight type, the key-value attributes of the connections are passed as strings to the C++ implementation. By default, custom connections require the same three values as \textit{DelayedConnection}: \textit{num\_connections}, \textit{efficacy}, and \textit{delay}. \textit{CustomConnectionParameters} can therefore be used with mesh algorithm nodes as well as grid algorithm nodes although MeshAlgorithm definitions must have the type attribute set to MeshAlgorithmCustom instead.

\begin{lstlisting}[language=xml,caption={A MeshAlgorithmCustom definition for use with WeightType=CustomConnectionParameters and a Connection using the num\_connections, efficacy, and delay attributes.}]
<WeightType>CustomConnectionParameters</WeightType>

<Algorithms>
...
<Algorithm type="MeshAlgorithmCustom" name="ALG_ADEX" modelfile="adex.model" >
	<TimeStep>0.001</TimeStep>
	<MatrixFile>adex_0.05_0_0_0_.mat</MatrixFile>
	<MatrixFile>adex_-0.05_0_0_0_.mat</MatrixFile>
</Algorithm>
...
</Algorithms>


<Connections>
...
<Connection In="ALG_ADEX" Out="RG_E" num_connections="1" efficacy="0.05" delay="0.0"/>
...
</Connections>
\end{lstlisting}

Other combinations of attributes for connections using CustomConnectionParameters are available for use with specific specialisations of the grid algorithm which are discussed in section \ref{gridalgospec} of the supplementary material. Any number of attributes are permitted but they will only be used if there is an algorithm specialisation implemented in the MIIND code base.

\subsection{SimulationRunParameter}

The \textit{\textless SimulationRunParameter\textgreater} block contains parameter settings for the simulation as a whole. The sub-elements listed in Table \ref{tab:simulationparameters} are required for a full definition. Although most of the sub-elements are self explanatory, \textit{t\_step} has the limitation that it must match or be an integer multiple of all time steps defined by any MeshAlgorithm and GridAlgorithm instances. \textit{master\_steps} is used only for the GPGPU implementation of MIIND (section \ref{mainmiindgpu}). It allows the user to set the number of Euler iterations per time step to solve the master equation. By default, the value is 10. However, to improve accuracy or to avoid blow-up in the case where the time step is too large or the local dynamics are unstable, \textit{master\_steps} should be increased. 

\subsection{Reporting}

The \textit{\textless Reporting\textgreater} block is used to describe how output is displayed and recorded from the simulation. There are three ways to record output from the simulation: Density, Rate, and Display. The \textit{\textless Rate\textgreater} element takes the node \textit{name} and \textit{t\_interval} as attributes and creates a single file in the output directory. \textit{t\_interval} must be greater than or equal to the simulation time step. At each \textit{t\_interval} of the simulation, the output activity of the population is recorded on a new line of the generated file. Although the element is called ``Rate'', if average membrane potential has been chosen as the activity of this population, this is what will be recorded here. \textit{\textless Density\textgreater} is used to record the full probability density of the given population node. As density is only relevant for the population density technique, it can only be recorded from nodes which instantiate the mesh or grid algorithm types. The attributes are the node \textit{name}, \textit{t\_start}, \textit{t\_end}, and \textit{t\_interval} which define the simulation times to start and end recording the density at the given interval. A file which holds the probability mass values for each cell in the mesh or grid will be created in the output directory for each \textit{t\_interval} between \textit{t\_start} and \textit{t\_end}. Finally, the \textit{\textless Display\textgreater} element can be used to observe the evolution of the probability density function as the simulation is running. If a \textit{Display} element is added in the XML file for a specific node, when the simulation is run, a graphical window will open and display the probability density for each time step. Again, display is only applicable to algorithms involving densities. Enabling the display can significantly slow the simulation down. However, it is useful for debugging the simulation and furthermore, each displayed frame is stored in the output directory so that a movie can be made of the node’s behaviour. How to generate this movie is discussed later in section \ref{densitymovie}.

\begin{lstlisting}[language=xml,caption={A set of reporting definitions to record the probability densities and rates of two populations, S and D. The densities will also be displayed during simulation.}]
<Reporting>
...
	<Density node="S" t_start="0.0" t_end="6.0" t_interval="0.01" />
	<Density node="D" t_start="0.5" t_end="1.5" t_interval="0.001" />
	<Display node="S" />
	<Display node="D" />
	<Rate node="S" t_interval="0.0001" />
	<Rate node="D" t_interval="0.0001" />
...
</Reporting>
\end{lstlisting}

\subsection{Variables}
\label{variables}
The \textit{\textless Simulation\textgreater} element can contain multiple \textit{\textless Variable\textgreater} sub-elements each with a unique name and value. Variables are provided for the convenience of the user and can replace any values in the XML file. For example, a variable named \textit{TIME\_END} can be defined to replace the value in the \textit{t\_end} element of the \textit{SimulationRunParameter} block. When the simulation is run, the value of \textit{t\_end} will be replaced with the default value provided in the Variable definition. Using variables makes it easy to perform parameter sweeps where the same simulation is run multiple times and only the variable's value is changed. How parameter sweeps are performed is covered in the supplementary material section \ref{parametersweeps}.
All values in a MIIND XML script can be set with a variable name. The type of the Variable is implicit and an error will be thrown if, say, a non-numerical value is passed to the tau\_refractive attribute of a MeshAlgorithm object.

\begin{lstlisting}[language=xml,caption={A Variable definition. TIME\_END has a default value of 18.0 and is used in the \textit{t\_end} parameter definition.}]
<Variable Name='TIME_END'>18.0</Variable>
...
<t_end>TIME_END</t_end>
\end{lstlisting}

\section{MIIND on the GPU}
\label{mainmiindgpu}
The population density techniques of the mesh and grid algorithms rely on multiple applications of the transition matrix which can be performed on each cell in parallel. This makes the algorithms prime candidates for parallelisation on the graphics card. In the CPU versions, the probability mass is stored in separate arrays, one for each population/node in the simulation. For the GPGPU version, these are concatenated into one large probability mass vector so all cells in all populations can be processed in parallel. From the user’s perspective, switching between CPU and GPU implementations is trivial. In the XML file for a simulation which uses MeshAlgorithm or GridAlgoirithm, to switch to the vectorised GPU version, the Algorithm types must be changed to MeshAlgorithmGroup and GridAlgorithmGroup. All other attributes remain the same. Only MeshAlgorithmGroup, GridAlgorithmGroup, and RateFunctor/RateAlgorithm types can be used for a vectorised simulation. When running a MIIND simulation containing a group algorithm from a Python script, instead of importing \textit{miind.miindsim}, \textit{miind.miindsimv} should be used. The Python module \textit{miind.run} is agnostic to the use of group algorithms so can be used as shown previously.

\begin{lstlisting}[language=xml,caption={A MeshAlgorithmGroup definition is identical to a MeshAlgorithm definition except for the type.}]
<Algorithm type="MeshAlgorithmGroup" name="ALG_ADEX" modelfile="adex.model" >
	<TimeStep>0.001</TimeStep>
	<MatrixFile>adex_0.05_0_0_0_.mat</MatrixFile>
	<MatrixFile>adex_-0.05_0_0_0_.mat</MatrixFile>
</Algorithm>
<Algorithm type="GridAlgorithmGroup" name="OSC" modelfile="fn.model" tau_refractive="0.0" transformfile="fn_0_0_0_0_.tmat" start_v="-1.0" start_w="-0.3" ratemethod="AvgV">
<TimeStep>0.00001</TimeStep>
</Algorithm>
\end{lstlisting}

The GPGPU implementation uses the Euler method to solve the master process during each iteration. It is, therefore, susceptible to blow-up if the time step is large or if the local dynamics of the model are stiff. The user has the option to set the number of euler steps taken each iteration using the \textit{master\_steps} value of the SimulationRunParameter block in the XML file. A higher value reduces the likelihood of blow-up but increases the simulation time. 
 
In order to run the vectorised simulations, MIIND must be running on a CUDA enabled machine and have CUDA enabled in the installation (CUDA is supported in the Windows and Linux python installations). Section \ref{cudaimplement} in the supplementary material goes into greater detail about the systems architecture differences between the CPU and GPU versions of the MIIND code. Using the ``Group'' algorithms is recommended if possible as it provides a significant performance increase. Benchmarking details for MIIND compared to direct simulation are available in \cite{de2019computational}.

\section{Running a MIIND Simulation in Python}
\label{miindpython}
As demonstrated in the quick start guide, the command \textbf{python -m miind.run} takes a simulation XML file as a parameter and runs the simulation. A similar script may be written by the user to give more control over what happens during a simulation and how output activity is recorded and processed. It even allows MIIND simulations to be integrated into other Python applications such as the Virtual Brain \citep{sanz2013virtual} so the population density technique can be used to solve the behaviour of nodes in a brain-scale network (see section \ref{tvbintegration}). To run a MIIND simulation in a Python script, the module \textit{miind.miindsim} must be imported (or \textit{miind.miindsimv} if the simulation uses MeshAlgorithmGroup or GridAlgorithmGroup and therefore requires CUDA support). Listing \ref{listing:miindpython} shows an example script which uses the following available functions to control the simulation.

\begin{lstlisting}[language=python,caption={A simple python script for running a MIIND simulation and plotting the results.}\label{listing:miindpython}]
import matplotlib.pyplot as plt
import miind.miindsim as miind

miind.init(1, "lif.xml")

timestep = miind.getTimeStep()
simulation_length = miind.getSimulationLength()
print('Timestep from XML : {}'.format(timestep))
print('Sim time from XML : {}'.format(simulation_length))

miind.startSimulation()

constant_input = [2500]
activities = []
for i in range(int(simulation_length/timestep)):
    activities.append(miind.evolveSingleStep(constant_input)[0])

miind.endSimulation()

plt.figure()
plt.plot(activities)
plt.title("Firing Rate.")

plt.show()
\end{lstlisting}

\subsection{init(node\_count,simulation\_xml\_file,...)}
The \textit{init} function should be called first once the MIIND library has been imported. This sets up the simulation ready to be started. The \textit{node\_count} parameter allows for multiple instantiations of the simulation to be run simultaneously. The Nodes, Connections, and Reporting blocks from the simulation file will be duplicated, effectively running the same model \textit{node\_count} times simultaneously in the same simulation. This functionality was included to allow the Virtual Brain to run the simulation defined in the XML file multiple times (see section \ref{tvbintegration}). The \textit{simulation\_xml\_file} parameter gives the name of the simulation xml file to be run. If the file has any variables defined, these are made available in Python as additional parameters to the \textit{init} function. In this way, the use of XML variables can be used for parameter sweeps. All variables must be passed as strings. If a variable is not set in the call to \textit{init}, the default value defined in the XML file will be used.

\begin{lstlisting}[caption={Calling init for a MIIND simulation lif.xml with the Variable SIM\_TIME set to 0.4.}]
miind.init(1, "lif.xml", SIM_TIME="0.4")
\end{lstlisting}

\subsection{getTimeStep() and getSimulationLength()}
Once \textit{init} has been called, the functions \textit{getTimeStep} and \textit{getSimulationLength} can be used to extract the time step and simulation length in seconds from the simulation respectively. The Python script controls when each iteration of the MIIND simulation is called and so it needs to know the total number of iterations to make. Furthermore, it can be useful for integration with other systems to know these values.

\subsection{startSimulation()}
\textit{startSimulation} indicates in the Python script that the simulation should be initialised ready for the simulation loop to be called.

\subsection{evolveSingleStep(input)}
By calling \textit{evolveSingleStep} in the Python script, the MIIND simulation will move forward one time step. This function takes a list of numbers as a parameter. The list corresponds to inputs to the population nodes in the MIIND simulation. In this way, the user may control the behaviour of the simulation from the Python script during the simulation. The \textit{evolveSingleStep} function also returns a list of numbers which are the output activities of the population nodes. Section \ref{externalconnections} provides more information about how to use the input and output of this function. \textit{evolveSingleStep} should be called in a loop which will run the same number of iterations as would be expected if the XML file were run in MIIND directly, that is, the simulation length divided by the time step.

\subsection{endSimulation()}
It is good practice to call \textit{endSimulation} once all iterations of the simulation have been performed. This allows MIIND to clean up and to print the performance statistics to the console.

\subsection{Additional XML Code for Python Support}
\label{externalconnections}
Although it is still possible to use \textit{RateFunctor} or \textit{RateAlgorithm} to set input rates to populations in a Python MIIND simulation, \textit{evolveSingleStep()} provides a means to pass the input rates as a parameter so that more complex input patterns can be used. In order to indicate that a population will receive input externally from the Python script (via the list input to \textit{evolveSingleStep()}) a special connection type must be defined in the \textit{\textless Connections\textgreater} section of the XML.

\begin{lstlisting}[caption={Special connection types for use in Python.}\label{lst:pythonconnections}]
<Connections>
...
<IncomingConnection Node="E">1 0.01 0</IncomingConnection>
<OutgoingConnection Node="E"/>
...
</Connections>
\end{lstlisting}

Listing \ref{lst:pythonconnections} defines an input to node E which will be interpreted as a DelayedConnection with the number of connections equal to 1 and a post synaptic efficacy of 0.01. No delay is defined here although it is permitted. OutgoingConnections are used to declare which nodes in the population network will pass their activity back to the Python script after each iteration. If the two connections in the listing are the only instances of IncomingConnection and OutgoingConnection, then the \textit{evolveSingleStep} function will expect as a parameter, a list with one numeric value to represent the incoming rate to node E. \textit{evolveSingleStep} will return a list with a single numeric value representing the activity of node E. In cases where there are more than one IncomingConnection, the order of values in the Python list parameter to \textit{evolveSingleStep} is the same as the order of IncomingConnections defined in the XML. Similarly with OutgoingConnections, the order of the list of activities returned from \textit{evolveSingleStep} is the same as the order of declaration in the XML file.

\section{Using the CLI to Quickly View Results}
\label{workflow}
Once a simulation has been run, either using \textit{miind.run} or from a user written Python script, the \textit{miind.miindio} CLI can be used to quickly plot the recorded results. As mentioned, the commands used in \textit{miindio} are based on the module \textit{miind.miind\_api} and are reproducible in a Python script. However, it can be convenient to be able to run them directly from the command line to aid fast prototyping and bug fixing of models and simulations. The following section lists some common commands in the CLI and their usage. The accompanying files for this example are in the \textit{examples/cli\_plots} directory. The following command starts the CLI and presets the user with a prompt:

\begin{lstlisting}[language=xml,caption={Run the CLI.}]
$ python -m miind.miindio
\end{lstlisting}

When \textit{miind.miindio} is called for the first time in a working directory, the user must identify the XML file which will describe the current working simulation. MIIND stores a reference to this file in a settings file in the working directory so that all subsequent commands will reference this simulation. Even if \textit{miind.miindio} is quit and restarted, the current working simulation will be used as the context for commands until a new current working simulation is defined or if it is called in a different directory. The user can set the current working simulation with the \textbf{sim} command. 

\begin{lstlisting}[language=xml,caption={Load a simulation file in the CLI.}]
> sim example.xml
\end{lstlisting}

Calling \textbf{sim} without a parameter will list information about the current working simulation such as the output directory, XML file name and provide a list of the defined variables and nodes.

During the simulation, MIIND generates output files according to the requirements of the \textit{\textless Recording\textgreater} object of the XML file which could include the average firing rate of population nodes or their densities at each time interval. The average firing rate can be plotted from the CLI using the \textbf{rate} command followed by the name of the population node. To be reminded of the node names, the user can call \textbf{sim} or \textbf{rate} without parameters.

\begin{lstlisting}[language=xml,caption={Plot the rate of population POP1 in the CLI.}]
> rate POP1
\end{lstlisting}

Even while a simulation is running, calling \textbf{rate} in the CLI will plot the recorded activity up to the latest simulated time point. This is useful to keep an eye on the simulation as it progresses without waiting for completion. An example of the plots produced by \textbf{rate} is shown in Fig. \ref{fig:rate_density_marginal}A.

For populations using the grid or mesh algorithms, the user can call the \textbf{plot-density} command with parameters identifying the required node name and simulation time. 

\begin{lstlisting}[language=xml,caption={Plot the probability density of population POP1 at time 0.42s in the CLI.}]
> plot-density POP1 0.42
\end{lstlisting}

This command renders the mesh or grid and its population density at the given simulation time. When reading the simulation time parameter in the command, MIIND expects the time to be an integer multiple of the time step and to be expressed up to its least significant figure (for example, 0.1 instead of 0.10). Again, this command can be run during a simulation providing the time has been simulated. An example of a density plot is shown in Fig. \ref{fig:rate_density_marginal}B.

Similar to \textbf{plot-density}, \textbf{plot-marginals} can be used to display the marginal densities of a given population at a given time. Both marginals are plotted next to each other. The details of how marginal densities are calculated are explained in the supplementary material section \ref{marginalsdensities}. Fig. \ref{fig:rate_density_marginal}C shows an example of a marginal density plot.

\begin{lstlisting}[language=xml,caption={Plot the marginal distributions of population POP1 at time 0.42s in the CLI.}]
> plot-marginals POP1 0.42
\end{lstlisting}

\subsection{Generate a Density Movie}
\label{densitymovie}
If, in the XML file \textit{\textless Recording\textgreater} section, the \textit{\textless Display\textgreater} element is added for a given population, the output directory will be populated with still images of density plots at each time step. Once the simulation is complete, calling \textbf{generate-density-movie} in the CLI will produce an MP4 movie file made from the still images. The parameters are the node name followed by the size of the square video frame in pixels. The third parameter is the desired time to display each image (every time step of the simulation) in seconds. If the video should be the same length as the simulation time, then this parameter should match the time step of the simulation. By changing the value, the video time can be altered. For example, if the parameter is set to 0.01 for a simulation with time step 0.001, then the video length will be 10 times the length of the simulation. Finally, a name for the video file must be given.

\begin{lstlisting}[language=xml,caption={Generate a movie from the display images of population POP1 with a size of 512 pixels at a simulation replay time step of 0.1s.}]
> generate-density-movie POP1 512 0.1 pop1_mov
\end{lstlisting}

The movie file will be created in the working directory of the simulation. A movie of the marginal density plots can also be created using the \textbf{generate-marginal-movie} command which takes the same parameters. As each marginal plot must be generated from the density output, this takes a considerably longer time than for the density movie.

\begin{lstlisting}[language=xml,caption={Generate a marginals movie from the density files of population POP1 with a size of 512 pixels at a simulation replay time step of 0.1s.}]
> generate-marginal-movie POP1 512 0.1 pop1_marginal_mov
\end{lstlisting}

\section{Description of MIIND's architecture and functionality}
The main architectural concerns in MIIND relate to the two C++ libraries, MPILib and TwoDLib. MPILib is responsible for instantiating and running the simulation. TwoDLib contains the CPU implementations of the grid and mesh algorithms. It is also responsible for generating transition matrices. Of the remaining libraries, GeomLib contains a population density technique implementation of neuron models with one time dependent variable, although it is also possible and indeed preferable to use the TwoDLib code for one dimensional models. EPFLLib and NumtoolsLib contain helper classes and type definitions. Fig. \ref{fig:uml} shows a reduced UML diagram of the MIIND C++ architecture. The aim of this section is to give a brief overview of the C++ MIIND code as a starting point for developers. The CUDA implementation of MIIND is similar in structure to the CPU solution and is available in the CudaTwoDLib and MiindLib libraries. A description of the differences is given in section \ref{cudaimplement} of the supplementary material.

\subsection{MPILib}

The MPINetwork class in MPILib represents a simulation as a whole and is instantiated in the \textit{init} function of the SimulationParserCPU class which is a specialisation of MiindTvbModelAbtract. \textit{init} is called from the Python module and, as the name suggests, MiindTvbModelAbtract was originally written with the aim of Python integration into TVB. MPINetwork exposes member functions for building a network of nodes where each node is an instance of a neuron population which can be connected together so that the output activity from one population is input to another. The class also contains all of the simulation parameters such as the simulation length and time step. Finally, the MPINetwork class exposes a function to run the simulation in its entirety or take a single evolve step for use in an external control loop.

Each node in the population network is represented by an instance of the MPINode class. A node has a name and an ID which is used to uniquely identify it in the simulation. A node also contains an implementation of AlgorithmInterface performing the integration technique required for this population (for example, GridAlgorithm or MeshAlgorithm). The \textit{NodeType} describes whether a population should be thought of as excitatory or inhibitory. As discussed earlier, MIIND performs a validation check that the synaptic efficacy from a node is positive or negative respectively (or neutral). During each iteration, each node is responsible for consolidating the activity of all input connections, calling the integration step in the AlgorithmInterface implementation, and reporting the density and output activity (the average firing rate or membrane potential).

In MPILib, a number of implementations of AlgorithmInterface are defined which can be instantiated in a node. Implementations of AlgorithmInterface are responsible for the lion's share of the computation in MIIND as this is where the integration of the model is performed. The interface is extremely simple, providing a function to set parameters, an optional function for a preamble before each iteration, and the \textit{evolveNodeState} function to be called every time step. GridAlgorithm and MeshAlgorithm are implementations of this interface defined in TwoDLib. MPILib and GeomLib hold the implementations of the remaining algorithms available to the user which were discussed in section \ref{section:xmlfile}. Finally, the weight types, DelayedConnection and CustomConnectionParameters are also defined in MPILib. All classes are C++ templates which take the weight type as a parameter to avoid code duplication and to enforce that only algorithms with the same weight type can be used together.

\subsection{TwoDLib}
As with the population models in MPILib and GeomLib, GridAlgorithm and MeshAlgorithm are implementations of the AlgorithmInterface. We will focus here on the grid algorithm implementation although the mesh algorithm uses the same structures or specialisations of those structures to perform similar tasks as set out in section \ref{miindoverview}. GridAlgorithm is supported by two important classes. \textbf{Ode2DSystem} transfers probability mass according to the reset mapping of the \textit{.model} file and calculates the average firing rate of the population. In MeshAlgorithm, Ode2DSystem also performs the pointer update for shifting probability mass down the strips of the mesh. \textbf{MasterGrid} is responsible for solving the Poisson master equation using a transition matrix calculated at simulation time based on the desired efficacy and grid cell size. For each iteration, the function \textit{evolveNodeState} is called which performs the main steps of the population density algorithm. 

First, in GridAlgorithm, the deterministic dynamics are solved by applying the pre-generated transition matrix once. The second step is a call to \textit{Ode2DSystem.RedistributeProbability()} to perform any reset mappings for probability mass which appeared in the threshold cells last iteration. This step is useful for neuron models, such as leaky integrate and fire, which contain an instruction to reset one or more variables to a different value upon reaching a threshold.

The third step calls on the MasterGrid class to solve the master equation for the incoming Poisson spike rates from every incident node. MasterGrid begins with the current state of the probability mass distribution across the grid, that is, the probability mass values of each cell in the grid. As described in section \ref{gridalgorithm}, every cell has the same relative transition of probability mass due to a single incoming spike. For the whole grid, this single transition is duplicated into a transition matrix which can be applied to the full probability mass vector. Because there are at most two cells into which probability mass is transferred, this matrix is extremely sparse and can be stored efficiently in a compressed sparse row (CSR) matrix. In the mesh algorithm, this matrix is loaded from the \textit{.mat} file.

MeshAlgorithm requires a fourth step to transfer probability mass from the ends of strips to stationary cells subject to a reversal mapping generated during the pre-processing phase. This is discussed in the supplementary material section \ref{suppl:meshbuilding}.

Finally, SimulationParserCPU is an extension of the MiindTvbModelAbstract class used to parse the simulation XML file and instantiate an MPINetwork object with the appropriate nodes and connections. Its extensions of the functions declared in MiindTvbModelAbstract are exposed to the Python module to be called from a Python script. 

\section{Discussion}

\subsection*{MIIND fulfills a need for insight into neural behaviour at mesoscopic scales.}
The MIIND population density technique allows researchers to simulate population level behaviour by defining the behaviour of the underlying neurons. This is in contrast to many rate based models which describe the population behaviour directly. An example of how population behaviour can differ from the underlying neuron model can be seen in the behaviour of a population of bursting neurons such as the Izhikevich simple model. A single Izhikevich neuron with a constant input current or input spike rate oscillates between a bursting period of repeated firing and a quiescent period of no firing. The average behaviour of a population of Izhikevich neurons is different. Initially, all neurons are synchronised, they burst and quiesce at the same time producing an oscillatory pattern of average firing rate in the population. However, due to the random nature of Poisson input spikes, the neurons de-synchronise over time and the average firing rate of the whole population damps to a constant value because only a subset of neurons are bursting at any one time. Fig. \ref{fig:rate_density_marginal}A shows the damping of the output firing rate oscillations and the `desynchronised' density of a population of Izhikevich simple neurons.

\subsection*{TVB Integration}
\label{tvbintegration}
The Virtual Brain \citep{sanz2013virtual} and MIIND are both systems which facilitate the development of neural mass or mean field population models with explicit descriptions of how multiple populations are connected. Using these systems, the complex dynamics arising from the interaction of populations can be studied.
TVB provides a framework to describe a network of nodes (the connectivity) which, while it can be abstract, generally represents regions of the human or primate brain. Connections between nodes represent white matter tracts which transfer signals from one node to the next based on length and propagation speed. TVB also allows the description of ``coupling'' functions which modulate these signals as they pass from one node to another. Typically, the number of nodes is in the order of 100 or so. However, TVB also allows for the definition of a ``surface'' which can be associated with 10s of thousands of nodes to simulate output from common medical recording techniques such as EEG and BOLD fMRI. TVB has impressive clinical relevance as well as supporting more theoretical neuroscience research. Users can build simulations using the graphical user interface or directly using the Python source code.

While MIIND and TVB have many functional similarities, both have differing strengths with respect to the underlying simulation techniques and surrounding infrastructure. It was therefore clear that integrating the smaller system, MIIND, into the more developed infrastructure of TVB might yield benefits from both.

Although it is possible to model delayed connections and synaptic dynamics between populations in MIIND, TVB provides a comprehensive method of defining such structures and behaviours through the connectivity network and coupling functions. Some users of MIIND may find it useful and appropriate to house their simulations in such a structure.

TVB uses a number of model classes to describe the behaviour of the nodes in a network. When the simulation is run, an instantiation of a specified model class takes the signals which have passed through the network to arrive at each node and integrates forward by one time step (depending on the integration method). In order to use MIIND nodes in TVB, a specialised model class was created to import the MIIND Python library, instantiate it, then make a call to \textit{evolveSingleStep()} in place of the integration function. The inputs and outputs of \textit{evolveSingleStep()} are treated by TVB as any other model. As the MIIND Python library takes a simulation file name as a parameter to its \textit{init} function, a single additional model class is all that is required to expose any MIIND simulation to TVB. Fig. \ref{fig:tvbmiind} shows the results from a simulation of the TVB default whole-brain connectivity with populations of Izhikevich simple neurons in MIIND. The script and simulation files are available in the \textit{examples/miind\_tvb} directory of the MIIND repository. Both TVB and MIIND must be installed to sucessfully run the example. 

\subsection*{Reasoning about probability density instead of populations of individual neurons simplifies output analysis.}
The output firing rate or membrane potential of a MIIND population which uses the the mesh algorithm or grid algorithm is devoid of any variation which you would see from a population of individual neurons. This is because the effect of Poisson generated input spike trains is applied to a probability density function, effectively an infinite population of neurons. Spike train inputs to a finite population of neurons produces variation in how individual neurons move through state space resulting in noisy output rates at the population level. While this can be mitigated using a larger number of neurons, the use of smoothing techniques, or curve fitting, MIIND requires none of these methods to produce an output which is immediately clear to interpret. For example, MIIND was used to build and simulate a spinal circuit model using populations of integrate and fire neurons \citep{york2019muscles}. The average firing rates of the populations were used to compare patterns of activity with results from an EMG experiment. As the patterns to be observed were on the order of seconds, there was no need to capture faster variation in activity from the simulation and indeed, a direct simulation would have produced output which may have obscured these patterns.

MIIND has also been used to simulate central pattern generator models which rely on mutually inhibiting populations of bursting neurons. The interaction of the two populations significantly influences their sub-threshold dynamics. In particular, it can be difficult to identify the dynamics responsible for the swapping of states from bursting to quiescent (escape or release). Observing the changing probability density function during the simulation makes it very clear how the two populations are behaving.

\subsection*{Handling Noise}
\label{handlingnoise}
A major benefit of MIIND's population density technique is the ability to observe the effect of noise on a population, and to manipulate noise in an intuitive way. For a given simulation, the Poisson distributed input to a population causes a spread of probability mass across the state space as some neurons receive many spikes, and some receive fewer. It is explained in \cite{de2013generic} how the Poisson input causes a mean increase in membrane potential equal to the product of the post synaptic efficacy, $h$, and the average input rate, $\nu$. It causes a variance equal to $\nu h$\texttwosuperior. $h$ and $\nu$ can therefore be set such that the mean remains the same but the variance changes to observe the effect of noise on the population.

Another simple way to increase the variance of the population is to introduce two additional inputs with equal rates and opposite post-synaptic efficacies. Again, the mean increase caused by the input remains unchanged but the variance can be increased significantly and this requires only a small change to the XML simulation file.\\

\subsection*{A model agnostic system at the population level makes prototyping quick and intuitive.}
Because MIIND provides insight of how a neuron model produces behaviour at the population level, it is beneficial that the grid algorithm enables the user to quickly reproduce the \textit{.model} and \textit{.tmat} files if the underlying neuron model needs to be changed. An example of this can be observed in a half-centre oscillator made of a pair of mutually inhibiting populations of bursting neurons. The frequency of oscillation can be made dependent or independent of the input spike rate by including a limit on the slow excitability variable of the underlying neuron model. To make this change, the user can alter the neuron model then rebuild the \textit{.model} and \textit{.tmat} file and no change to the population level network is required.\\

\subsection*{DiPDE}
DiPDE \citep{dipdewebsite,iyer2013influence} is an alternative implementation of the population density technique for one dimensional neuron models. It does not employ the ``mesh'' discretisation method used in the MIIND mesh algorithm and has primarily been used with populations of leaky integrate and fire neurons. DiPDE can be used to simulate the Potjans-Diesmann microcircuit model \citep{cain2016computational} which shows good agreement with MIIND (Fig. \ref{fig:potjans}). MIIND is a much larger application than DiPDE because it allows users to design their own underlying neuron models for each population using either the mesh or grid algorithms. \\

\subsection*{Future Work}
A limitation on the MIIND population density technique is that a maximum of two time-dependent variables can be used to describe the underlying neuron model of each population. In the mesh algorithm, for higher dimensions, mesh building would need to be automated but this is not a trivial problem to solve. The grid algorithm, however, is entirely automated and work has been done to extend MIIND for 3D neuron models. Fig. \ref{fig:hindmarshrose} shows the 3D density plot of a population of Hindmarsh-Rose neurons in MIIND. The technique used to generate the 2D transition matrices outlined in section \ref{gridalgorithm} extends to N dimensions so there is theoretically no limit to the dimensionality of the underlying neuron model in the grid algorithm. However, both the grid algorithm and mesh algorithm suffer from ``the curse of dimensionality'' such that with each additional variable, the number of cells to cover the state space increases to the point where the memory and processing requirements are too high. Luckily, a great number of neuron behaviours can be captured with only two or three time-dependent variables with appropriate approximations.

 Large networks can be built up quickly in MIIND. To add a node to a simulation file requires just a single line. Integrating the node into the rest of the network with requisite connections is equally convenient. As mentioned, the Potjans-Diesmann model has been implemented as a single cortical column but this is by no means the limit of the size of network which can be built. It is feasible that a patch of cortex made of perhaps hundreds of cortical columns can be simulated efficiently in MIIND. The benefit of such a network would be to demonstrate how cortical columns interact together under different connectivity regimes and inputs as well as providing the ability to quickly and easily ``swap out'' the underlying neuron model of each population. Typically, LIF is used but adaptive integrate and fire would be a closer approximation to pyramidal neurons in cortex.
 
 \subsection*{Conclusion}
 We have reintroduced MIIND's population density techniques for simulating populations of neurons and given a full account of the features available to users. While the mesh algorithm was developed some time ago, the grid algorithm which was added to MIIND recently has precipitated a more accessible, user friendly software package. We hope that the explanations given here along with a lower technical barrier to entry will encourage researchers to make use of the tool. 

\section*{Conflict of Interest Statement}
%All financial, commercial or other relationships that might be perceived by the academic community as representing a potential conflict of interest must be disclosed. If no such relationship exists, authors will be asked to confirm the following statement: 

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

\section*{Author Contributions}

HO and MdK contributed to the text of this article. YML, MEL, DS, and LD contributed to the development of the population density technique and MIIND software.  

\section*{Funding}
This project received funding from the European Union’s Horizon 2020 research and innovation programme under Grant Agreement No. 720270 (HBP SGA1) and Specific Grant Agreement No. 785907 (Human Brain Project SGA2) (MdK; YML). HO is funded by EPSRC. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.

\section*{Acknowledgments}
The authors wish to thank Frank van der Velde and Martin Perez-Guevara for their continued support of the MIIND project.

\section*{Data Availability Statement}
The MIIND source code and installation packages are available as a github repository at \url{https://github.com/dekamps/miind}.

MIIND can be installed for use in Python using ``pip install miind'' on many Linux, MacOS, and Windows machines with python versions \textgreater= 3.6.

Documentation is available at \url{https://miind.readthedocs.io/}.
% Please see the availability of data guidelines for more information, at https://www.frontiersin.org/about/author-guidelines#AvailabilityofData

\bibliographystyle{frontiersinSCNS_ENG_HUMS} % for Science, Engineering and Humanities and Social Sciences articles, for Humanities and Social Sciences articles please include page numbers in the in-text citations
%\bibliographystyle{frontiersinHLTH&FPHY} % for Health, Physics and Mathematics articles
\bibliography{test}

\newpage

%%% Make sure to upload the bib file along with the tex file and PDF
%%% Please see the test.bib file for some examples of references

\section*{Tables}

\begin{table}[ht!]
\caption{Parameters for the \textit{grid\_generate.generate} function.}
    \centering
    \begin{tabular}{|p{0.2\linewidth} | p{0.75\linewidth}|}
    \hline
    &\\
    Parameter Name & Notes \\
    \hline
    &\\
    \textit{func} & The underlying neuron model function.\\
    \textit{timestep} & The desired time step for the neuron model\\
    \textit{timescale} & A scale factor for the timescale of the underlying neuron model to convert the time step into seconds.\\
    \textit{tolerance} & An error tolerance for solving a single time step of the neuron model.\\
    \textit{basename} & The base name with which all output files will be named.\\
    \textit{threshold\_v} & The spike threshold value for integrate and fire neuron models.\\
    \textit{reset\_v} & The reset value for integrate and fire neuron models.\\
    \textit{reset\_shift\_h} & A value for increasing the second variable during reset for integrate and fire neuron models with some adaptive shift or similar function.\\
    \textit{grid\_v\_min} & The minimum value for the first dimension of the grid (usually membrane potential).\\
    \textit{grid\_v\_max} & The maximum value for the first dimension of the grid.\\
    \textit{grid\_h\_min} & The minimum value for the second dimension of the grid.\\
    \textit{grid\_h\_max} & The maximum value for the second dimension of the grid.\\
    \textit{grid\_v\_res} & The number of columns in the grid.\\
    \textit{grid\_h\_res} & The number of rows in the grid.\\
    \textit{efficacy\_orientation} & The direction, `v' or `h', in which incoming spikes cause an instantaneous change. \\
    \hline
    \end{tabular}
\label{tab:gridgenerate}
\end{table}

\begin{table}[ht!]
\caption{Parameters for the \textbf{generate-model} command in the CLI.}
    \centering
    \begin{tabular}{|p{0.2\linewidth} | p{0.75\linewidth}|}
    \hline
    &\\
    Parameter Name & Notes \\
    \hline
    &\\
    \textit{basename} & The shared name of the \textit{.mesh}, \textit{.stat}, \textit{.rev} and generated \textit{.model} files.\\
    \textit{reset} & The value (usually representing membrane potential) which probability mass will be transferred to having passed the threshold.\\
    \textit{threshold} & The value (usually representing membrane potential) beyond which probability mass will be transferred to the reset value.\\
    \hline
    \end{tabular}
\label{tab:generatemodel}
\end{table}

\begin{table}[ht!]
\caption{Parameters for the \textbf{generate-matrix} command in the CLI.}
    \centering
    \begin{tabular}{|p{0.2\linewidth} | p{0.75\linewidth}|}
    \hline
    &\\
    Parameter Name & Notes \\
    \hline
    &\\
    \textit{basename} & The shared name of the \textit{.model}, \textit{.fid} (if required), and generated \textit{.mat} files.\\
    \textit{v\_efficacy} & The efficacy value in the $v$ (membrane potential) direction. If the parameter \textit{h\_efficacy} is used, this should be zero.\\
    \textit{points / precision} & For Monte Carlo, this gives the number of points per cell to use for approximating the transition matrix. For the geometric method, transitions are stored in the \textit{.mat} file to the nearest $\frac{1}{precision}$\\
    \textit{h\_efficacy} & The efficacy value in the $h$ direction. If the parameter \textit{v\_efficacy} is used, this should be zero.\\
    \textit{reset-shift} & The shift in the $h$ direction which neurons take when being reset. \\
    \textit{use\_geometric} & A boolean flag set to ``true'' if the geometric method is used and ``false'' for Monte Carlo. \\
    \hline
    \end{tabular}
\label{tab:generatematrix}
\end{table}

\begin{table}[ht!]
\caption{Compatible weight types for each algorithm type defined in the simulation XML file.}
    \centering
    \begin{tabular}{|p{0.25\linewidth} | p{0.1\linewidth} | p{0.22\linewidth} | p{0.32\linewidth} |}
    \hline
    &&&\\
    Algorithm Name & double & DelayedConnection & CustomConnectionParameters \\
    \hline
    &&&\\
    \textit{RateAlgorithm} & \checkmark & \checkmark & \checkmark\\
    \textit{MeshAlgorithm} & & \checkmark & \\
    \textit{MeshAlgorithmCustom} & & & \checkmark\\
    \textit{GridAlgorithm} & & & \checkmark\\
    \textit{GridJumpAlgorithm} & & & \checkmark\\
    \textit{OUAlgorithm} & & \checkmark & \\
    \textit{WilsonCowanAlgorithm} & \checkmark & & \\
    \textit{RateFunctor} & \checkmark & \checkmark & \checkmark\\
    \hline
    \end{tabular}
\label{tab:algorithmweighttypes}
\end{table}

\begin{table}[ht!]
\caption{The required sub-elements for the \textit{SimulationRunParameter} section of the XML simulation file.}
    \centering
    \begin{tabular}{|p{0.2\linewidth} | p{0.75\linewidth}|}
    \hline
     &\\
    Element & Notes \\
    \hline
     &\\
    \textit{SimulationName} & The name of the simulation.\\
    \textit{t\_end} & The simulation end time.\\
    \textit{t\_step} & The time step of the simulation.\\
    \textit{name\_log} & A file name for logging. The file is stored in the output directory of the simulation.\\
	\textit{master\_steps} & The number of Euler iterations per time step used to solve the mater equation in the GPGPU implementation. \\
    \hline
    \end{tabular}
\label{tab:simulationparameters}
\end{table}

\clearpage

\section*{Figures}

%%% Please be aware that for original research articles we only permit a combined number of 15 figures and tables, one figure with multiple subfigures will count as only one figure.
%%% Use this if adding the figures directly in the mansucript, if so, please remember to also upload the files when submitting your article
%%% There is no need for adding the file termination, as long as you indicate where the file is saved. In the examples below the files (logo1.eps and logos.eps) are in the Frontiers LaTeX folder
%%% If using *.tif files convert them to .jpg or .png
%%%  NB logo1.eps is required in the path in order to correctly compile front page header %%%

\begin{figure}[htb!]
  \centering
    \includegraphics[width=\linewidth]{images/cloud_full_figure.pdf}
  \caption{(A) The state space of a conductance based point model neuron. It is spanned by two variables: the membrane potential and a variable representing how open the channel is. This channel has an equilibrium potential that is positive. The green dots represent the state of individual neurons in a population. They are the result of the direct simulation of a group of neurons. MIIND, however, produces the heat plot representing a density which predicts where neurons in the population are likely to be: most likely in the white areas, least likely in  the red areas and not at all in the black areas. The sharp vertical cut of the coloured area at -55mV represents the threshold at which neurons are removed from state space. They are subsequently inserted at the reset potential, at their original conductance state value. (B) The state space of a Fitzhugh-Nagumo neuron model. The axes have arbitrary units for variables $V$ and $W$. There is no threshold-reset mechanism and the density follows a limit cycle. After a certain amount of simulation time, neurons can be found at all points along the limit cycle as shown here by a consistently high brightness.}
  \label{fig-cloud}
\end{figure}

\begin{figure}[htb!]
  \centering
  \includegraphics[width=\linewidth]{images/cond_full_figure.pdf}
  \caption{The display output of a running E-I population network simulation of conductance based neurons. (A) The probability density heat map of the excitatory population. (B) The probability density heat map of the inhibitory population. Brighter colours indicate a larger probability mass. The axes are unlabelled in the simulation windows as the software is agnostic to the underlying model. However, the membrane potential and conductance labels have been added for clarity. (C) The average firing rate of the excitatory population.}
  \label{fig:quickstart}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=\columnwidth]{images/grid_method.pdf}
  \caption{The state space of a neuron model (shown here as a vector field) is discretised into a regular grid of cells. (A) The transition matrix for solving the deterministic dynamics of the population is generated by applying a single time step of the underlying neuron model to each vertex of each cell in the grid and calculating the proportion by area to each overlapping cell. Once the vertices of a grid cell have been translated, the resulting polygon is recursively triangulated according to intersections with the original grid. Once complete, all triangles can be assigned to a cell and the area proportions can be summed. (B) For a single incoming spike (with constant efficacy), all cells are translated by the same amount and therefore have the same resulting transition which can be used to solve the Poisson master equation. In fact, the transition will always involve at most two target cells and the proportions can be calculated knowing only the grid cell width and the efficacy.}
  \label{fig:grid}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.9\columnwidth]{images/reset_grid.pdf}
  \caption{For each time step, probability mass in the cells which lie across the threshold (threshold cells) is pushed onto the beginning of the refractory queue. There is one queue per threshold cell. During each subsequent time step, the probability mass is shifted one place along the queue until it reaches the penultimate place. A proportion of the mass, calculated according to the modulo of the refractory time and the time step, is transferred to the appropriate reset cell. The remaining mass is shifted to the final place in the queue. During the next time step, that remaining mass is transferred to the reset cell.}
  \label{fig:basicreset}
\end{figure}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=0.6\linewidth]{images/potjans_full_figure.pdf}
  \caption{(A) A representation of the connectivity between populations in the Potjans-Diesmann microcircuit model. Each population shows the probability density at an early point in the simulation before all populations have reached a steady state. All populations are of leaky-integrate-and-fire neurons and so the density plots show membrane potential in the horizontal axis. The vertical axis has no meaning (probability mass values are the same at all points along the vertical). (B) The firing rate outputs from MIIND (crosses) in comparison to those from DiPDE for the same model (solid lines).}
  \label{fig:potjans}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.6\columnwidth]{images/grid_cond_comp.pdf}
  \caption{Comparison of average firing rates from four simulations of a single population of conductance based neurons. The black solid and dashed lines indicate MIIND simulations using the grid algorithm with different grid resolutions. The red crosses show the average firing rate of a direct simulation of 10,000 neurons.}
  \label{fig:gridcomp}
\end{figure}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=\linewidth]{images/error_full_figure.pdf}
  \caption{(A) In the grid algorithm, large cells cause probability mass to be distributed further than it should. This error is expressed most clearly in models where the the average firing rate of the population is highly dependent on the amount of probability mass passing through an area of slow dynamics. (B) In the mesh algorithm, when cells become shear, probability mass which is pushed to the right due to incoming spikes also moves laterally (downwards) because it is spread evenly across each cell.}
  \label{fig:meshissue}
\end{figure}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=\linewidth, valign=t]{images/vector_field_full_figure.pdf}
  \caption{(A) A vector field of the FitzHugh-Nagumo neuron model \citep{fitzhugh1961impulses}. Arrows show the direction of motion of states through the field according to the dynamics of the model. The red broken dashed nullcline indicates where the change in $V$ is zero. The blue dashed nullcline indicates where the change in $W$ is zero. The green solid line shows a potential path (trajectory) of a neuron in the state space. (B) A vector field for the adaptive exponential integrate and fire neuron model \citep{brette2005}. Two strips are shown which follow the dynamics of the model and approach the stationary point where the nullclines cross. A strip is constructed between two trajectories in state space. Each time step of the two trajectories is used to segment the strip into cells. Because the strips approach a stationary point, they get thinner as the trajectories converge to the same point and cells get closer together as the distance in state space travelled reduces per time step (neurons slow down as they approach a stationary point). Per time step, probability mass is shifted from one cell to the next along the strip. (C) The state space of the Izhikevich simple neuron model \citep{izhikevich2003simple} which has been fully discretised into strips and cells.}
  \label{fig:strip}
\end{figure}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=\linewidth]{images/density_full_figure.pdf}
  \caption{Heat plots for the probability density functions of two populations in MIIND. Brightness (more yellow) indicates a higher probability mass. (A) When the Poisson master equation is solved, probability mass is pushed to the right (higher membrane potential) in discrete steps. As time passes, the discrete steps are smoothed out due to the movement of mass according to the deterministic dynamics (following the strip). (B) A combination of mass travelling along strips and being spread across the state space by noisy input produces the behaviour of the population.}
  \label{fig:desities}
\end{figure}

\begin{figure}[!htb]
\centering
    \includegraphics[width=\linewidth]{images/mesh_workflow.pdf}
  \caption{The MIIND processes and generated files required at each stage of pre-processing for the mesh algorithm. The shaded green rectangles represent automated processes run via the MIIND CLI.}
  \label{fig:meshworkflow}
\end{figure}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=\linewidth]{images/izh_full_figure.pdf}
  \caption{(A) The average firing rate of a population produced by calling the \textbf{rate} command. (B) A density plot of the population produced by calling the \textbf{plot-density} command. (C) The marginal density plots produced by calling the \textbf{plot-marginals} command.}
  \label{fig:rate_density_marginal}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=\columnwidth]{images/miind_uml.pdf}
  \caption{A minimal UML diagram of MIIND. The two major libraries, MPILib and TwoDLib, are represented.}
  \label{fig:uml}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.7\columnwidth]{images/tvb_miind.pdf}
  \caption{The firing rates of 76 nodes from the default TVB connectivity simulation. Each node is a population of Izhikevich simple neurons simulated using MIIND. The majority of nodes produce oscillations which decay to a constant average firing rate. However, a subset of nodes remain in an oscillating state. }
  \label{fig:tvbmiind}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.7\columnwidth]{images/hindmarsh-rose.png}
  \caption{(A) A density plot of a population of Hindmarsh-Rose neurons. The density is contained in a three dimensional volume such that each axis represents one of the time-dependent variables of the model. The volume has been rendered from a rotated and elevated position to more easily visualise the density.}
  \label{fig:hindmarshrose}
\end{figure}

%%% If you are submitting a figure with subfigures please combine these into one image file with part labels integrated.
%%% If you don't add the figures in the LaTeX files, please upload them when submitting the article.
%%% Frontiers will add the figures at the end of the provisional pdf automatically
%%% The use of LaTeX coding to draw Diagrams/Figures/Structures should be avoided. They should be external callouts including graphics.

\end{document}
